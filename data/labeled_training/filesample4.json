[
  {
    "text": "This ICCV workshop paper is the Open Access version, provided by the Computer Vision Foundation. Except for this watermark, it is identical to the accepted version; the final published version of the proceedings is available on IEEE Xplore.",
    "bbox": {
      "x0": 152.4453125,
      "y0": 1.7956790924072266,
      "x1": 489.682861328125,
      "y1": 36.3979606628418
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.34,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 38,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 71.41603469848633,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "POSTER: A Pyramid Cross-Fusion Transformer Network for Facial Expression Recognition",
    "bbox": {
      "x0": 61.168907165527344,
      "y0": 107.81399536132812,
      "x1": 555.7881469726562,
      "y1": 140.4157257080078
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 14.49,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 10,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 25.630630493164062,
    "vertical_space_before": 71.41603469848633,
    "label": "title",
    "language": "en"
  },
  {
    "text": "Ce Zheng, Matias Mendieta, Chen Chen Center for Research in Computer Vision, University of Central Florida",
    "bbox": {
      "x0": 138.0489501953125,
      "y0": 166.04635620117188,
      "x1": 478.9191589355469,
      "y1": 192.2123565673828
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 12.07,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 16,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 3.864013671875,
    "vertical_space_before": 25.630630493164062,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "{ ce.zheng,matias.mendieta } @ucf.edu, chen.chen@crcv.ucf.edu",
    "bbox": {
      "x0": 151.6810760498047,
      "y0": 196.0763702392578,
      "x1": 465.2747802734375,
      "y1": 205.51205444335938
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusMonL-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 5,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 30.111953735351562,
    "vertical_space_before": 3.864013671875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Abstract",
    "bbox": {
      "x0": 155.34332275390625,
      "y0": 235.62400817871094,
      "x1": 200.27346801757812,
      "y1": 247.69876098632812
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 12.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -10.497787475585938,
    "vertical_space_before": 30.111953735351562,
    "label": "H1",
    "language": "ca"
  },
  {
    "text": "learning, as evidenced by the popularity of methods such as RAN [ 40 ], SCN [ 39 ], and KTN [ 20 ]. These approaches have beneﬁted from large-scale datasets that provide suf- ﬁcient training data from challenging real-world scenarios and have shown signiﬁcant performance improvement over traditional methods.",
    "bbox": {
      "x0": 314.2904968261719,
      "y0": 237.2009735107422,
      "x1": 552.9061279296875,
      "y1": 307.6365661621094
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 49,
    "line_count": 6,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -44.984405517578125,
    "vertical_space_before": -10.497787475585938,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Facial expression recognition (FER) is an important task in computer vision, having practical applications in ar- eas such as human-computer interaction, education, health- care, and online monitoring. In this challenging FER task, there are three key issues especially prevalent: inter-class similarity, intra-class discrepancy, and scale sensitivity. While existing works typically address some of these issues, none have fully addressed all three challenges in a uniﬁed framework. In this paper, we propose a two-stream Pyramid crOss-fuSion TransformER network (POSTER), that aims to holistically solve all three issues. Speciﬁcally, we design a transformer-based cross-fusion method that enables ef- fective collaboration of facial landmark features and image features to maximize proper attention to salient facial re- gions. Furthermore, POSTER employs a pyramid structure to promote scale invariance. Extensive experimental results demonstrate that our POSTER achieves new state-of-the- art results on RAF-DB (92.05%), FERPlus (91.62%), as well as AffectNet 7 class (67.31%) and 8 class (63.34%). Code is available at https://github.com/zczcwh/ POSTER .",
    "bbox": {
      "x0": 58.50127410888672,
      "y0": 262.65216064453125,
      "x1": 297.126953125,
      "y1": 514.2078247070312
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-ReguItal",
    "is_bold": false,
    "is_italic": true,
    "word_count": 159,
    "line_count": 21,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -203.582763671875,
    "vertical_space_before": -44.984405517578125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Despite the great progress made so far, there are still sev- eral challenges remain in FER: • Inter-class similarity: Similar images with subtle changes between them can be classiﬁed into different expression categories. As illustrated in Fig. 1 (a), A small change in a speciﬁc region of an image, such as the mouth, can determine the expression category, even when the overall appearance remains largely unchanged. Due to the sub- tlety of these differences, current methods may not be suf- ﬁciently robust to differentiate between such images. • Intra-class discrepancy: Within the same expression cate- gory, images can have signiﬁcant differences, such as the skin tone, gender, and age of a person varies across sam- ples, as well as image background appearance. As shown in Fig. 1 (b), two images both represent the expression of happiness but have very different visual appearances. • Scale sensitivity: When naively applied, deep-learning based networks are often sensitive to image quality and resolution. The image sizes within FER datasets and with in-the-wild testing images vary considerably. Therefore, ensuring consistent performance across scales is critical in FER [ 37 ].",
    "bbox": {
      "x0": 314.2904968261719,
      "y0": 310.62506103515625,
      "x1": 552.9160766601562,
      "y1": 575.3218994140625
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 185,
    "line_count": 22,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -32.399169921875,
    "vertical_space_before": -203.582763671875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "1. Introduction",
    "bbox": {
      "x0": 58.501495361328125,
      "y0": 542.9227294921875,
      "x1": 136.10592651367188,
      "y1": 554.9974365234375
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 12.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 9.97052001953125,
    "vertical_space_before": -32.399169921875,
    "label": "H1",
    "language": "en"
  },
  {
    "text": "Facial expression recognition (FER) is a critical task in computer vision, as it plays a crucial role in understanding human emotions and intentions. FER has various practical applications in ﬁelds such as human-computer interaction, education, healthcare, and online monitoring. Thus, it has received increasing interest in recent years, as highlighted in the comprehensive survey by Li et al. [ 21 ].",
    "bbox": {
      "x0": 58.501380920410156,
      "y0": 564.9679565429688,
      "x1": 297.1270751953125,
      "y1": 647.4781494140625
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 61,
    "line_count": 7,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -69.0771484375,
    "vertical_space_before": 9.97052001953125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "In light of these issues, some early works, some ear- lier works [ 17 , 15 ] (prior to 2018) attempted to improve the attention to detail and promote invariance to intra-class discrepancies by incorporating facial landmarks into their deep-learning based FER methods. These facial landmarks refer to a set of keypoints on the human face image that pro- vide a sparse representation of key facial regions to comple- ment direct image features . However, these methods typi- cally only use simple concatenation to combine the image and landmark features before the last fully connected layer or prior to a set of basic blocks. While incorporating fa- cial landmarks with image features has potential to allevi-",
    "bbox": {
      "x0": 314.2904968261719,
      "y0": 578.4010009765625,
      "x1": 552.9061889648438,
      "y1": 721.2846069335938
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 116,
    "line_count": 12,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -70.435546875,
    "vertical_space_before": -69.0771484375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Traditional approaches [ 46 , 47 ] utilize handcrafted fea- tures such as Histogram of oriented Gradients (HOG) [ 9 ], Local Binary Patterns (LBP) [ 32 ], and SIFT [ 26 ] for FER[ 4 , 3 , 31 ]. However, these handcrafted features are of- ten not sufﬁciently robust and accurate. More recent ap- proaches have focused on leveraging the power of deep",
    "bbox": {
      "x0": 58.501380920410156,
      "y0": 650.8490600585938,
      "x1": 297.1270446777344,
      "y1": 721.2845458984375
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 65,
    "line_count": 6,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 30.23846435546875,
    "vertical_space_before": -70.435546875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3146",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 1,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 30.23846435546875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "tion granularities. With our cross-fusion transformer de- sign and integration of a feature pyramid structure, we fully address all three issues in a uniﬁed framework to bridge this research gap and achieve new SOTA results on several popular benchmarks.",
    "bbox": {
      "x0": 313.94842529296875,
      "y0": 72.32501983642578,
      "x1": 552.5642700195312,
      "y1": 130.68594360351562
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 39,
    "line_count": 5,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -54.225006103515625,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "D \u0003,QWHU\u0010FODVV\u0003VLPLODULW\\\u0003 GLIIHUHQW\u0003 FDWHJRULHV E \u0003,QWUD\u0010FODVV\u0003GLVFUHSDQF\\\u0003 VDPH \u0003FDWHJRU\\ 1HXWUDO +DSSLQHVV +DSSLQHVV",
    "bbox": {
      "x0": 64.95018005371094,
      "y0": 76.4609375,
      "x1": 287.7159729003906,
      "y1": 92.21585083007812
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.85,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 11,
    "line_count": 5,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -6.219207763671875,
    "vertical_space_before": -54.225006103515625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "+DSSLQHVV",
    "bbox": {
      "x0": 132.211669921875,
      "y0": 85.99664306640625,
      "x1": 156.57069396972656,
      "y1": 91.97708129882812
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.85,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 40.81550598144531,
    "vertical_space_before": -6.219207763671875,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "Overall, our contributions are summarized as follows: • We propose a Pyramid crOss-fuSion TransformER net-",
    "bbox": {
      "x0": 313.94842529296875,
      "y0": 132.79258728027344,
      "x1": 552.5640258789062,
      "y1": 154.98988342285156
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 15,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 2.012420654296875,
    "vertical_space_before": 40.81550598144531,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "work (POSTER) to alleviate inter-class similarity, intra- class discrepancy, and scale sensitivity issues in the FER. • The cross-fusion transformer structure ensures that image features can be guided by landmark features with prior attention to salient facial regions, while landmark features can utilize global information provided by image features beyond landmarks. • We extensively validate the efﬁciency and effectiveness",
    "bbox": {
      "x0": 313.94842529296875,
      "y0": 157.00230407714844,
      "x1": 552.5841064453125,
      "y1": 251.58729553222656
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 59,
    "line_count": 8,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -33.84974670410156,
    "vertical_space_before": 2.012420654296875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "LPDJHV\u0003DUH\u0003VLPOLDU\u000f\u0003ODQGPDUNV\u0003KLJKOLJKW\u0003GLIIHUHQFHV\u0003 LPDJHV\u0003DUH\u0003GLIIHUHQW\u000f\u0003ODQGPDUNV\u0003DUH\u0003VLPOLDU",
    "bbox": {
      "x0": 64.88072204589844,
      "y0": 217.737548828125,
      "x1": 282.0654296875,
      "y1": 223.03688049316406
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.18,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 6.615509033203125,
    "vertical_space_before": -33.84974670410156,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "Figure 1. Inter-class similarity and intra-class discrepancy. (The facial landmarks are detected by [ 16 ].)",
    "bbox": {
      "x0": 58.340267181396484,
      "y0": 229.6523895263672,
      "x1": 296.9493713378906,
      "y1": 249.7749786376953
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 16,
    "line_count": 2,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 3.824737548828125,
    "vertical_space_before": 6.615509033203125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "of our proposed POSTER. We show that POSTER out- performs previous state-of-the-art methods on three com- monly used datasets. (92.05% on RAF-DB, 67.31% on AffectNet, and 91.62% on FERPlus.)",
    "bbox": {
      "x0": 322.5013122558594,
      "y0": 253.59971618652344,
      "x1": 552.5640869140625,
      "y1": 299.8859558105469
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 29,
    "line_count": 4,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -36.673675537109375,
    "vertical_space_before": 3.824737548828125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "ate intra-class discrepancies and inter-class similarities, just simple concatenation is insufﬁcient for exploring the cor- relations between landmarks and image features. More- over, recent works [ 30 , 42 ] address only intra-class dis- crepancy and inter-class similarity issues using image fea- tures, while another [ 37 ] addresses only scale sensitivity, with none fully addressing all three challenges in FER . No- tably, landmark features, widely used in face-related tasks, have been largely ignored by recent FER approaches.",
    "bbox": {
      "x0": 58.340267181396484,
      "y0": 263.2122802734375,
      "x1": 296.9660339355469,
      "y1": 369.87188720703125
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 79,
    "line_count": 10,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -57.283233642578125,
    "vertical_space_before": -36.673675537109375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "2. Related Work",
    "bbox": {
      "x0": 313.9497985839844,
      "y0": 312.5886535644531,
      "x1": 397.8934631347656,
      "y1": 324.6634216308594
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 12.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 3,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 8.624725341796875,
    "vertical_space_before": -57.283233642578125,
    "label": "H1",
    "language": "en"
  },
  {
    "text": "Deep learning in FER: With the rapid progress of deep learning in computer vision, such techniques have been found increasingly useful for the challenging FER task [ 44 , 45 ]. Wang et al. [ 40 ] proposed a Region Attention Net- work (RAN) to capture facial regions for occlusion and pose variant FER. Farzaneh and Qi [ 12 ] introduced a Deep Atten- tive Center Loss (DACL) method to estimate the attention weight for the features for enhancing the discrimination. A sparse center loss was designed to achieve intra-class com- pactness and inter-class separation with the weighted fea- tures. Wang et al. [ 39 ] proposed a Self-Cure Network (SCN) to suppress uncertainty, which prevents the network from overﬁtting incorrectly labeled samples. Shi et al. [ 34 ] designed an Amending Representation Module (ARM) to reduce the weight of eroded features and decompose facial features to simplify representation learning.",
    "bbox": {
      "x0": 313.9496765136719,
      "y0": 333.28814697265625,
      "x1": 552.5653686523438,
      "y1": 524.5143432617188
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 150,
    "line_count": 18,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -150.15472412109375,
    "vertical_space_before": 8.624725341796875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Therefore, in this paper, we propose a Pyramid crOss- fuSion TransformER network (POSTER) to tackle all three challenges of inter-class similarity, intra-class discrepancy, and scale sensitivity in FER. POSTER is a two-stream ar- chitecture that consists of an image stream and a landmark stream. Landmarks pinpoint salient regions and can serve as a guide for focusing feature attention, helping allevi- ate the inter-class similarity issue. As shown in Fig. 1 (a), the salient region (mouth area) indicating the happiness ex- pression is more easily captured through the discrepancy of landmarks rather than general image features. Also, the sparse landmark features can help to reduce the intra-class discrepancy because they are less sensitive in regard to var- ious skin tones, genders, ages, and background appearance (image features may be affected signiﬁcantly). On the other hand, image features contain global information of the en- tire image that landmarks do not cover (such as cheeks, forehead, or a tears drop). Motivated by these intuitions, we propose to explore the correlations between landmark and image features with POSTER. Speciﬁcally, we design a transformer-based cross-fusion block that effectively allows the two streams to guide each other, and enables global cor- relation across features through attention. Experiments val- idate that the proposed cross-fusion transformer mechanism successfully alleviates inter-class similarity and intra-class discrepancy. Furthermore, to solve the scale-sensitivity for FER, we incorporate a pyramid architecture [ 24 ] with the cross-fusion transformer network to capture various resolu- tions of the extracted feature maps with different informa-",
    "bbox": {
      "x0": 58.340267181396484,
      "y0": 374.359619140625,
      "x1": 296.9659729003906,
      "y1": 722.5126342773438
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 249,
    "line_count": 29,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -195.9794921875,
    "vertical_space_before": -150.15472412109375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Facial landmarks in FER: Facial landmark detection aims to estimate the location of predeﬁned keypoints on the human face. The detected facial landmarks are used in many face analysis tasks such as face recognition [ 35 , 25 ], face tracking [ 19 ], and emotion recognition [ 17 , 15 , 29 ]. Signiﬁcant progress has been made by employing deep learning techniques in the facial landmark detection task, and many accurate facial landmark detectors such as [ 38 , 41 , 5 , 16 ] have been proposed. Taking advantage of these off-the-shelf detectors, researchers have paid more attention to utilizing facial landmarks as informative features for the FER task. Jung et al. [ 17 ] proposed two networks, where one receives the image as input and another receives facial landmark as input. The output of the two networks is in- tegrated by weighted summation. Hassani et al. [ 15 ] pro- posed a 3D Inception-ResNet where facial landmarks are",
    "bbox": {
      "x0": 313.9496765136719,
      "y0": 526.5331420898438,
      "x1": 552.5753784179688,
      "y1": 717.7593994140625
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 162,
    "line_count": 16,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 33.76361083984375,
    "vertical_space_before": -195.9794921875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3147",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 2,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 33.76361083984375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "head Self-Attention Layer (MSA) in the transformer archi- tecture. The input X fuse ∈ R 2 P × D is ﬁrst mapped to three matrices: the query matrix Q , key matrix K and value ma- trix V by three linear transformations:",
    "bbox": {
      "x0": 313.9745788574219,
      "y0": 72.28844451904297,
      "x1": 552.5919799804688,
      "y1": 115.5588607788086
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 42,
    "line_count": 4,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -43.267669677734375,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "multiplied with image features at certain layers. Khan [ 18 ] used the facial landmarks to crop small regions ﬁrst, then generate features as the input for the neural networks. How- ever, existing methods that utilize facial landmarks ignore the correlations of landmark features and image features. Among SOTA methods [ 33 , 34 , 42 ] in the FER task, none of them use facial landmarks.",
    "bbox": {
      "x0": 58.29265594482422,
      "y0": 72.29119110107422,
      "x1": 296.9082946777344,
      "y1": 154.80140686035156
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 67,
    "line_count": 7,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -28.54106903076172,
    "vertical_space_before": -43.267669677734375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Q = X fuse W Q , K = X fuse W K , V = X fuse W V , (1)",
    "bbox": {
      "x0": 324.0030212402344,
      "y0": 126.26033782958984,
      "x1": 552.5853271484375,
      "y1": 136.3223876953125
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "CMMI9",
    "is_bold": false,
    "is_italic": true,
    "word_count": 22,
    "line_count": 4,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 8.551788330078125,
    "vertical_space_before": -28.54106903076172,
    "label": "NONE",
    "language": "fr"
  },
  {
    "text": "where W Q , W K and W V ∈ R D × D .",
    "bbox": {
      "x0": 316.4886169433594,
      "y0": 144.87417602539062,
      "x1": 460.458740234375,
      "y1": 158.9235382080078
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI7",
    "is_bold": false,
    "is_italic": true,
    "word_count": 15,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -1.3285064697265625,
    "vertical_space_before": 8.551788330078125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Vision transformer: The breakthrough of transformer networks in Natural Language Processing (NLP) has sparked great interest in the computer vision domain. In NLP, the transformer is designed to model long sequence inputs. When adapting to the computer vision task, ViT [ 11 ] split the image into patches, then the self-attention mecha- nism in the transformer can capture long-range dependen- cies across these patches. In FER, Aouayeb et al. [ 1 ] di- rectly applied the ViT structure by adding a SE block before the MLP-head for the FER task. Xue et al. [ 42 ] proposed a transformer-based method named TransFER. After extract- ing feature maps with a backbone CNN, the local CNN blocks were designed to locate diverse local patches. Then, a transformer encoder explored the global relationship be- tween these local patches with a multi-head self-attention dropping module.",
    "bbox": {
      "x0": 58.29265594482422,
      "y0": 157.59503173828125,
      "x1": 296.9183654785156,
      "y1": 348.8212585449219
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 141,
    "line_count": 16,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -189.12254333496094,
    "vertical_space_before": -1.3285064697265625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "The vanilla transformer attention block is illustrated in Fig. 4 (a) can be described as the following mapping func- tion:",
    "bbox": {
      "x0": 313.97283935546875,
      "y0": 159.69871520996094,
      "x1": 552.5885009765625,
      "y1": 193.9102325439453
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 20,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 3.0751495361328125,
    "vertical_space_before": -189.12254333496094,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "√",
    "bbox": {
      "x0": 497.2597351074219,
      "y0": 196.98538208007812,
      "x1": 505.6415710449219,
      "y1": 207.047607421875
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMSY10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -3.009674072265625,
    "vertical_space_before": 3.0751495361328125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "d ) V, (2)",
    "bbox": {
      "x0": 505.6444396972656,
      "y0": 204.03793334960938,
      "x1": 552.584716796875,
      "y1": 216.5783233642578
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 4,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -12.539413452148438,
    "vertical_space_before": -3.009674072265625,
    "label": "NONE",
    "language": "ca"
  },
  {
    "text": "Attention( Q, K, V ) = Softmax( QK ⊤ /",
    "bbox": {
      "x0": 330.8069152832031,
      "y0": 204.03890991210938,
      "x1": 497.25970458984375,
      "y1": 216.11474609375
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 10,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 12.1163330078125,
    "vertical_space_before": -12.539413452148438,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "where 1 √",
    "bbox": {
      "x0": 313.9691162109375,
      "y0": 228.2310791015625,
      "x1": 349.224853515625,
      "y1": 240.30506896972656
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.04,
    "font_name": "CMR7",
    "is_bold": false,
    "is_italic": true,
    "word_count": 3,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -10.060943603515625,
    "vertical_space_before": 12.1163330078125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "d is the scaling factor for appropriate normalization to prevent extremely small gradients. Next, the vanilla transformer encoder architecture con- sisting of MSA and MLP with a layer normalization opera- tor is shown in Fig. 3 (a). The encoder output X fuse out ∈ R 2 P × D keeps the same size as the encoder input X fuse ∈ R 2 P × D , and is represented as follows:",
    "bbox": {
      "x0": 313.97149658203125,
      "y0": 230.24412536621094,
      "x1": 552.5970458984375,
      "y1": 314.289794921875
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 71,
    "line_count": 7,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 10.129791259765625,
    "vertical_space_before": -10.060943603515625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "X ′",
    "bbox": {
      "x0": 340.9792175292969,
      "y0": 324.4195861816406,
      "x1": 352.4248046875,
      "y1": 334.4818115234375
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -10.059967041015625,
    "vertical_space_before": 10.129791259765625,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "fuse = MSA( Q, K, V ) + X fuse , (3)",
    "bbox": {
      "x0": 349.318603515625,
      "y0": 324.4218444824219,
      "x1": 552.5895385742188,
      "y1": 338.9844665527344
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 12,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 1.768402099609375,
    "vertical_space_before": -10.059967041015625,
    "label": "NONE",
    "language": "et"
  },
  {
    "text": "X fuse out = MLP(Norm( X ′",
    "bbox": {
      "x0": 340.9809265136719,
      "y0": 340.75286865234375,
      "x1": 462.2491760253906,
      "y1": 354.3402099609375
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 7,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -13.5836181640625,
    "vertical_space_before": 1.768402099609375,
    "label": "NONE",
    "language": "fr"
  },
  {
    "text": "fuse )) + X ′",
    "bbox": {
      "x0": 459.1429748535156,
      "y0": 340.756591796875,
      "x1": 508.2991027832031,
      "y1": 355.0955810546875
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 5,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -14.3389892578125,
    "vertical_space_before": -13.5836181640625,
    "label": "NONE",
    "language": "es"
  },
  {
    "text": "fuse , (4)",
    "bbox": {
      "x0": 505.1929016113281,
      "y0": 340.756591796875,
      "x1": 552.5855102539062,
      "y1": 355.0955810546875
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 3,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -3.436767578125,
    "vertical_space_before": -14.3389892578125,
    "label": "NONE",
    "language": "fr"
  },
  {
    "text": "Compared to previous works, our POSTER employs a two-stream pyramid cross-fusion transformer network to explore the correlation of image features and landmark fea- tures to tackle inter-class similarity, intra-class discrepancy, and scale sensitivity issues simultaneously in FER.",
    "bbox": {
      "x0": 58.29265594482422,
      "y0": 351.6588134765625,
      "x1": 296.9083557128906,
      "y1": 410.01971435546875
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 37,
    "line_count": 5,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -44.308807373046875,
    "vertical_space_before": -3.436767578125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "where MSA( · ) represents the Multi-head Self-Attention block, Norm( · ) is the normalization operator, and MLP( · ) denotes the multilayer perceptron. Finally, an MLP head returns the predicted emotion label Y ∈ R N where N is the number of classes.",
    "bbox": {
      "x0": 313.9698181152344,
      "y0": 365.7109069824219,
      "x1": 552.5918579101562,
      "y1": 424.5364685058594
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 44,
    "line_count": 5,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 0.48602294921875,
    "vertical_space_before": -44.308807373046875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3. Methodology",
    "bbox": {
      "x0": 58.29265594482422,
      "y0": 425.0224914550781,
      "x1": 138.11883544921875,
      "y1": 437.0972595214844
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 12.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -10.27667236328125,
    "vertical_space_before": 0.48602294921875,
    "label": "H1",
    "language": "cy"
  },
  {
    "text": "Although the transformer encoders can inherently model the image features and landmark features jointly to some extent with simple concatenation of X img with X lm , the strong correlations between image features and landmark features are not fully exploited by the vanilla transformer since features are concatenated together. In the next section, we describe POSTER which improves the correlation and representation capability of the model.",
    "bbox": {
      "x0": 313.97613525390625,
      "y0": 426.8205871582031,
      "x1": 552.591796875,
      "y1": 521.4010009765625
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 66,
    "line_count": 8,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -75.67019653320312,
    "vertical_space_before": -10.27667236328125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3.1. Baseline",
    "bbox": {
      "x0": 58.29265594482422,
      "y0": 445.7308044433594,
      "x1": 117.02207946777344,
      "y1": 456.7992858886719
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 11.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 8.677825927734375,
    "vertical_space_before": -75.67019653320312,
    "label": "H2",
    "language": "et"
  },
  {
    "text": "First, we will describe our baseline architecture as shown in Fig. 2 (a). We deﬁne an input image X ∈ R H × W × 3 , where H and W are the height and width of the image, re- spectively. In the network, we begin with an image back- bone (e.g. IR50 [ 10 ]) to get image features X img ∈ R P × D . An off-the-shelf facial landmark detector (e.g. Mobile- FaceNe [ 7 ]) is used to obtain the landmark features X lm ∈ R P × D , where P is the number of patches (same as the num- ber of landmark keypoints) and D is the feature dimension, respectively. During training, the image backbone is ﬁne- tuned, while the off-the-shelf facial landmark detector is frozen to maintain proper landmark outputs.",
    "bbox": {
      "x0": 58.27911376953125,
      "y0": 465.47711181640625,
      "x1": 296.91192626953125,
      "y1": 608.36083984375
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 137,
    "line_count": 13,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -76.90020751953125,
    "vertical_space_before": 8.677825927734375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3.2. POSTER",
    "bbox": {
      "x0": 313.97271728515625,
      "y0": 531.4606323242188,
      "x1": 377.62762451171875,
      "y1": 542.5291137695312
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 11.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 8.11822509765625,
    "vertical_space_before": -76.90020751953125,
    "label": "H2",
    "language": "tl"
  },
  {
    "text": "The facial landmarks locate a set of keypoints in the hu- man face region, which pinpoints salient regions related to facial expression. At the same time, global information be- yond landmarks is also important for recognizing human expression (e.g. cheeks, wrinkled forehead). Motivated by this, we design a two-stream network that consists of both an image and a landmark stream. We swap the key matrices of the two streams, creating a cross-fusion opera- tion to facilitate feature collaboration. Speciﬁcally, by per- forming this operation, we enable the image features to be guided by some prior knowledge of salient regions from the landmarks. Likewise, the representations of the landmark stream are provided with global context from the image fea- tures while moving through the block operations. In this",
    "bbox": {
      "x0": 313.97259521484375,
      "y0": 550.6473388671875,
      "x1": 552.5883178710938,
      "y1": 717.6802978515625
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 127,
    "line_count": 16,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -108.9600830078125,
    "vertical_space_before": 8.11822509765625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "After obtaining the image features X img and landmark features X lm , an intuitive solution is to aggregate X img with X lm as the fused features X fuse ∈ R 2 P × D (concate- nate in patch dimension P ). The transformer architecture utilizes its self-attention mechanism to capture the correla- tions across patches. Thus, we directly apply transformer encoders (illustrated in Fig. 3 (a)) to operate on the fused features X fuse . The self-attention mechanism is achieved by the Multi-",
    "bbox": {
      "x0": 58.289405822753906,
      "y0": 608.72021484375,
      "x1": 296.913330078125,
      "y1": 717.6796264648438
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 85,
    "line_count": 9,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 33.8433837890625,
    "vertical_space_before": -108.9600830078125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3148",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 3,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 33.8433837890625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u000e\u0003 \u0003\u0003\u0003\u0003\u0003\u0003\u0003 3DWFK\u0010ZLVH\u0003FRQFDWHQDWLRQ \u0007 \b \u0003\u0003\u0003\u0003ODQGPDUN\u0003IHDWXUHV\u0003 \u0007 \u0003\u0003,PDJH\u0003IHDWXUHV",
    "bbox": {
      "x0": 382.03717041015625,
      "y0": 84.73320007324219,
      "x1": 504.8155822753906,
      "y1": 116.98304748535156
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.37,
    "font_name": "CambriaMath",
    "is_bold": true,
    "is_italic": false,
    "word_count": 8,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -22.01348114013672,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": ")DLFDO\u0003 ODQGPDUN",
    "bbox": {
      "x0": 177.4142303466797,
      "y0": 94.96956634521484,
      "x1": 204.94827270507812,
      "y1": 111.20600128173828
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -8.421699523925781,
    "vertical_space_before": -22.01348114013672,
    "label": "NONE",
    "language": "pt"
  },
  {
    "text": "\u0002 \u0006\u0004",
    "bbox": {
      "x0": 246.46075439453125,
      "y0": 102.7843017578125,
      "x1": 257.8677673339844,
      "y1": 111.15800476074219
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.18,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 1.3138809204101562,
    "vertical_space_before": -8.421699523925781,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "GHWHFWRU",
    "bbox": {
      "x0": 179.44834899902344,
      "y0": 112.47188568115234,
      "x1": 202.9243621826172,
      "y1": 119.95722198486328
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -0.7031097412109375,
    "vertical_space_before": 1.3138809204101562,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": ")DLFDO\u0003ODQGPDUNV",
    "bbox": {
      "x0": 300.10186767578125,
      "y0": 119.25411224365234,
      "x1": 350.1102294921875,
      "y1": 126.73944854736328
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 15.209815979003906,
    "vertical_space_before": -0.7031097412109375,
    "label": "NONE",
    "language": "pt"
  },
  {
    "text": "2XWSXW",
    "bbox": {
      "x0": 470.39898681640625,
      "y0": 141.9492645263672,
      "x1": 496.4403381347656,
      "y1": 151.5389862060547
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.37,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -6.5487518310546875,
    "vertical_space_before": 15.209815979003906,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "0/3",
    "bbox": {
      "x0": 442.7441711425781,
      "y0": 144.990234375,
      "x1": 459.8623352050781,
      "y1": 153.48782348632812
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 8.31,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -7.40704345703125,
    "vertical_space_before": -6.5487518310546875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 382.23712158203125,
      "y0": 146.08078002929688,
      "x1": 418.3979187011719,
      "y1": 153.5661163330078
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.3560943603515625,
    "vertical_space_before": -7.40704345703125,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "\u000e \u0002 \u0003\u0004\u0005",
    "bbox": {
      "x0": 244.74273681640625,
      "y0": 149.21002197265625,
      "x1": 304.8365783691406,
      "y1": 168.5229949951172
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 8.31,
    "font_name": "CambriaMath",
    "is_bold": true,
    "is_italic": false,
    "word_count": 3,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -13.691055297851562,
    "vertical_space_before": -4.3560943603515625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "HQFRGHUV",
    "bbox": {
      "x0": 387.3663635253906,
      "y0": 154.83193969726562,
      "x1": 413.2584228515625,
      "y1": 162.31727600097656
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -7.3260040283203125,
    "vertical_space_before": -13.691055297851562,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "KHDG",
    "bbox": {
      "x0": 443.4502258300781,
      "y0": 154.99127197265625,
      "x1": 459.16290283203125,
      "y1": 163.48886108398438
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 8.31,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -7.59893798828125,
    "vertical_space_before": -7.3260040283203125,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": ",PDJH EDFNERQH",
    "bbox": {
      "x0": 177.22030639648438,
      "y0": 155.88992309570312,
      "x1": 205.15675354003906,
      "y1": 172.1264190673828
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 6.176177978515625,
    "vertical_space_before": -7.59893798828125,
    "label": "NONE",
    "language": "ca"
  },
  {
    "text": "D \u0003%DVHOLQH",
    "bbox": {
      "x0": 284.57720947265625,
      "y0": 178.30259704589844,
      "x1": 331.1750183105469,
      "y1": 187.89231872558594
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.37,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 23.522262573242188,
    "vertical_space_before": 6.176177978515625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "&URVV\u0010IXVLRQ",
    "bbox": {
      "x0": 350.3624267578125,
      "y0": 211.41458129882812,
      "x1": 387.6390686035156,
      "y1": 218.89991760253906
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -2.179840087890625,
    "vertical_space_before": 23.522262573242188,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "\u0010",
    "bbox": {
      "x0": 423.710693359375,
      "y0": 216.72007751464844,
      "x1": 427.6155700683594,
      "y1": 223.46424865722656
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 6.74,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.5734100341796875,
    "vertical_space_before": -2.179840087890625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ")DLFDO\u0003ODQGPDUNV",
    "bbox": {
      "x0": 162.510498046875,
      "y0": 217.89083862304688,
      "x1": 212.51881408691406,
      "y1": 225.3761749267578
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -6.982635498046875,
    "vertical_space_before": -5.5734100341796875,
    "label": "NONE",
    "language": "pt"
  },
  {
    "text": "\u0002 \u000e\u000f",
    "bbox": {
      "x0": 417.66888427734375,
      "y0": 218.39353942871094,
      "x1": 439.1083068847656,
      "y1": 229.50709533691406
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.37,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -9.341293334960938,
    "vertical_space_before": -6.982635498046875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "7UDQVIRUPHU HQFRGHUV",
    "bbox": {
      "x0": 350.9112243652344,
      "y0": 220.16580200195312,
      "x1": 387.0647277832031,
      "y1": 236.4022979736328
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 13.585159301757812,
    "vertical_space_before": -9.341293334960938,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "&URVV\u0010IXVLRQ",
    "bbox": {
      "x0": 350.3442687988281,
      "y0": 249.98745727539062,
      "x1": 387.62091064453125,
      "y1": 257.4727783203125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -2.7089996337890625,
    "vertical_space_before": 13.585159301757812,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "\u0011",
    "bbox": {
      "x0": 425.7670593261719,
      "y0": 254.76377868652344,
      "x1": 429.67193603515625,
      "y1": 261.5079650878906
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 6.74,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.07080078125,
    "vertical_space_before": -2.7089996337890625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0002 \u000e\u000f",
    "bbox": {
      "x0": 419.7262268066406,
      "y0": 256.4371643066406,
      "x1": 441.1667175292969,
      "y1": 267.5507507324219
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.37,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -10.64276123046875,
    "vertical_space_before": -5.07080078125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ")DLFDO\u0003 ODQGPDUN",
    "bbox": {
      "x0": 153.43173217773438,
      "y0": 256.9079895019531,
      "x1": 180.97088623046875,
      "y1": 273.14447021484375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -14.405792236328125,
    "vertical_space_before": -10.64276123046875,
    "label": "NONE",
    "language": "pt"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 350.9150085449219,
      "y0": 258.7386779785156,
      "x1": 387.0758056640625,
      "y1": 266.2239990234375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 0.55596923828125,
    "vertical_space_before": -14.405792236328125,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "\u0002 \u0006\u0004",
    "bbox": {
      "x0": 227.47781372070312,
      "y0": 266.77996826171875,
      "x1": 238.8848114013672,
      "y1": 275.1537170410156
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.18,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -7.66387939453125,
    "vertical_space_before": 0.55596923828125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "HQFRGHUV",
    "bbox": {
      "x0": 356.04425048828125,
      "y0": 267.4898376464844,
      "x1": 381.9363098144531,
      "y1": 274.97515869140625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -0.564849853515625,
    "vertical_space_before": -7.66387939453125,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "GHWHFWRU",
    "bbox": {
      "x0": 155.4658660888672,
      "y0": 274.4103088378906,
      "x1": 178.94187927246094,
      "y1": 281.8956298828125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 10.723968505859375,
    "vertical_space_before": -0.564849853515625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "&URVV\u0010IXVLRQ",
    "bbox": {
      "x0": 351.0139465332031,
      "y0": 292.6195983886719,
      "x1": 388.29058837890625,
      "y1": 300.10491943359375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.747589111328125,
    "vertical_space_before": 10.723968505859375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "2XWSXW \u000e",
    "bbox": {
      "x0": 272.2136535644531,
      "y0": 294.3573303222656,
      "x1": 524.5101928710938,
      "y1": 311.8108825683594
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.37,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -13.65814208984375,
    "vertical_space_before": -5.747589111328125,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "0/3",
    "bbox": {
      "x0": 472.6876220703125,
      "y0": 298.1527404785156,
      "x1": 489.8041076660156,
      "y1": 306.65032958984375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 8.31,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -8.2916259765625,
    "vertical_space_before": -13.65814208984375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0012",
    "bbox": {
      "x0": 424.7257385253906,
      "y0": 298.35870361328125,
      "x1": 428.630615234375,
      "y1": 305.1028747558594
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 6.74,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.049835205078125,
    "vertical_space_before": -8.2916259765625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0002 \u000e\u000f",
    "bbox": {
      "x0": 418.6849670410156,
      "y0": 300.05303955078125,
      "x1": 440.1253967285156,
      "y1": 311.19287109375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.37,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -9.82208251953125,
    "vertical_space_before": -5.049835205078125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 351.5627136230469,
      "y0": 301.37078857421875,
      "x1": 387.7235107421875,
      "y1": 308.8561096191406
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.521820068359375,
    "vertical_space_before": -9.82208251953125,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": ",PDJH EDFNERQH",
    "bbox": {
      "x0": 153.23779296875,
      "y0": 307.33428955078125,
      "x1": 181.1742401123047,
      "y1": 323.57080078125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -15.416961669921875,
    "vertical_space_before": -1.521820068359375,
    "label": "NONE",
    "language": "ca"
  },
  {
    "text": "KHDG",
    "bbox": {
      "x0": 473.3936767578125,
      "y0": 308.1538391113281,
      "x1": 489.1063232421875,
      "y1": 316.65142822265625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 8.31,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -6.52947998046875,
    "vertical_space_before": -15.416961669921875,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "HQFRGHUV",
    "bbox": {
      "x0": 356.69195556640625,
      "y0": 310.1219482421875,
      "x1": 382.5840148925781,
      "y1": 317.6072692871094
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.32,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -7.44573974609375,
    "vertical_space_before": -6.52947998046875,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "\u0002 \u0003\u0004\u0005",
    "bbox": {
      "x0": 225.7598114013672,
      "y0": 310.1615295410156,
      "x1": 240.5852813720703,
      "y1": 318.5351867675781
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.18,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 15.0120849609375,
    "vertical_space_before": -7.44573974609375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "E \u00033267(5",
    "bbox": {
      "x0": 287.10821533203125,
      "y0": 333.5472717285156,
      "x1": 338.4043273925781,
      "y1": 343.1369934082031
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.37,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 6.9827880859375,
    "vertical_space_before": 15.0120849609375,
    "label": "NONE",
    "language": "es"
  },
  {
    "text": "Figure 2. The architectures of baseline (a) and our proposed POSTER (b) for Facial Expression Recognition (FER). A facial landmark detector (MobileFaceNet [ 7 ]) is applied to obtain landmark features X lm . The image backbone (IR50 [ 10 ]) is used to extract image features X img . “ + ” denotes patch-wise concatenation operation.",
    "bbox": {
      "x0": 57.91700744628906,
      "y0": 350.1197814941406,
      "x1": 557.875244140625,
      "y1": 381.31201171875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": true,
    "word_count": 57,
    "line_count": 3,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 7.427459716796875,
    "vertical_space_before": 6.9827880859375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": ">3\u000f\u0003'@",
    "bbox": {
      "x0": 324.980712890625,
      "y0": 388.7394714355469,
      "x1": 337.1747741699219,
      "y1": 394.08642578125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -1.112579345703125,
    "vertical_space_before": 7.427459716796875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "FRQFDWHQDWH\u0003LPDJH\u0003SDWFKHV\u0003",
    "bbox": {
      "x0": 77.02122497558594,
      "y0": 392.9738464355469,
      "x1": 122.55626678466797,
      "y1": 397.26104736328125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -3.82427978515625,
    "vertical_space_before": -1.112579345703125,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "0DW0XO 6FDOH 6RIW0D[ \u0013",
    "bbox": {
      "x0": 426.889404296875,
      "y0": 393.436767578125,
      "x1": 498.3439025878906,
      "y1": 404.38232421875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 4,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -8.3507080078125,
    "vertical_space_before": -3.82427978515625,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "/DQGPDUN",
    "bbox": {
      "x0": 323.9078063964844,
      "y0": 396.0316162109375,
      "x1": 338.2510681152344,
      "y1": 399.59625244140625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -2.071624755859375,
    "vertical_space_before": -8.3507080078125,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "SDWFK\u0003ZLVH FRQFDWHQDWH",
    "bbox": {
      "x0": 343.88653564453125,
      "y0": 397.5246276855469,
      "x1": 357.6102294921875,
      "y1": 403.9646911621094
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 2.89,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -6.038818359375,
    "vertical_space_before": -2.071624755859375,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "ǆ\u0003E",
    "bbox": {
      "x0": 276.2376708984375,
      "y0": 397.9258728027344,
      "x1": 281.68902587890625,
      "y1": 402.21307373046875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "Calibri",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.227020263671875,
    "vertical_space_before": -6.038818359375,
    "label": "NONE",
    "language": "es"
  },
  {
    "text": "ZLWK\u0003ODQGPDUN\u0003SDWFKHV",
    "bbox": {
      "x0": 80.8851318359375,
      "y0": 397.9860534667969,
      "x1": 118.67772674560547,
      "y1": 402.27325439453125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -2.060211181640625,
    "vertical_space_before": -4.227020263671875,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": ")HDWXUHV",
    "bbox": {
      "x0": 325.17266845703125,
      "y0": 400.2130432128906,
      "x1": 337.0001525878906,
      "y1": 403.7776794433594
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -1.165130615234375,
    "vertical_space_before": -2.060211181640625,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "4.9 (PEHGGLQJ )XVHG )HDWXUHV 2XW 0DW0XO",
    "bbox": {
      "x0": 364.2845764160156,
      "y0": 402.612548828125,
      "x1": 542.9917602539062,
      "y1": 411.66558837890625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 6,
    "line_count": 6,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -6.826812744140625,
    "vertical_space_before": -1.165130615234375,
    "label": "NONE",
    "language": "pl"
  },
  {
    "text": ".",
    "bbox": {
      "x0": 426.9186706542969,
      "y0": 404.8387756347656,
      "x1": 430.0078430175781,
      "y1": 409.5767517089844
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.63,
    "font_name": "TimesNewRomanPS-ItalicMT",
    "is_bold": false,
    "is_italic": true,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.76800537109375,
    "vertical_space_before": -6.826812744140625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "/0 /0 ,PJ ,PJ \u0011\u0011\u0011",
    "bbox": {
      "x0": 71.59257507324219,
      "y0": 405.8087463378906,
      "x1": 128.13758850097656,
      "y1": 412.0555419921875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 5,
    "line_count": 5,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.532501220703125,
    "vertical_space_before": -3.76800537109375,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "1RUP 06$ 1RUP 0/3",
    "bbox": {
      "x0": 153.14183044433594,
      "y0": 407.5230407714844,
      "x1": 256.1416320800781,
      "y1": 412.4787292480469
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.76,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 4,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.468505859375,
    "vertical_space_before": -4.532501220703125,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": ",PDJH )HDWXUHV",
    "bbox": {
      "x0": 325.1728820800781,
      "y0": 408.0102233886719,
      "x1": 337.0003662109375,
      "y1": 415.7562561035156
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -0.39642333984375,
    "vertical_space_before": -4.468505859375,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "\u0014",
    "bbox": {
      "x0": 427.0055236816406,
      "y0": 415.3598327636719,
      "x1": 429.9001770019531,
      "y1": 419.9913024902344
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.63,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.173736572265625,
    "vertical_space_before": -0.39642333984375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ">3\u000f\u0003'@ >\u00153\u000f\u0003'@ >\u00153\u000f\u0003'@",
    "bbox": {
      "x0": 324.980712890625,
      "y0": 416.81756591796875,
      "x1": 547.8941650390625,
      "y1": 425.2117004394531
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 3,
    "line_count": 3,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.61224365234375,
    "vertical_space_before": -3.173736572265625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "D \u00039DQLOOD\u0003\u0003WUDQVIRUPHU\u0003HQFRGHU",
    "bbox": {
      "x0": 135.90011596679688,
      "y0": 421.5994567871094,
      "x1": 202.026611328125,
      "y1": 426.4662780761719
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.76,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 0.617584228515625,
    "vertical_space_before": -3.61224365234375,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "D \u00039DQLOOD\u000306$\u0003EORFN",
    "bbox": {
      "x0": 398.1852111816406,
      "y0": 427.0838623046875,
      "x1": 447.39508056640625,
      "y1": 432.4308166503906
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.546630859375,
    "vertical_space_before": 0.617584228515625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "ǆ\u0003E",
    "bbox": {
      "x0": 276.7002258300781,
      "y0": 430.8841857910156,
      "x1": 282.1515808105469,
      "y1": 435.17138671875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "Calibri",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 2.895751953125,
    "vertical_space_before": -1.546630859375,
    "label": "NONE",
    "language": "es"
  },
  {
    "text": "\u0011\u0011\u0011",
    "bbox": {
      "x0": 97.73616790771484,
      "y0": 438.067138671875,
      "x1": 101.76287841796875,
      "y1": 443.5595703125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.37,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -3.07720947265625,
    "vertical_space_before": 2.895751953125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "1RUP 06$ 1RUP 0/3",
    "bbox": {
      "x0": 153.60446166992188,
      "y0": 440.48236083984375,
      "x1": 256.6042175292969,
      "y1": 445.43804931640625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.76,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 4,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.71038818359375,
    "vertical_space_before": -3.07720947265625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "/0 /0",
    "bbox": {
      "x0": 70.16087341308594,
      "y0": 440.7276611328125,
      "x1": 91.6336441040039,
      "y1": 445.0148620605469
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.287200927734375,
    "vertical_space_before": -4.71038818359375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "/0",
    "bbox": {
      "x0": 107.01250457763672,
      "y0": 440.7276611328125,
      "x1": 113.28821563720703,
      "y1": 445.0148620605469
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.287200927734375,
    "vertical_space_before": -4.287200927734375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ",PJ",
    "bbox": {
      "x0": 121.86620330810547,
      "y0": 440.7276611328125,
      "x1": 128.5999755859375,
      "y1": 445.0148620605469
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -2.403167724609375,
    "vertical_space_before": -4.287200927734375,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "0DW0XO 6FDOH 6RIW0D[ \u0013 \u0003\u0004\u0005",
    "bbox": {
      "x0": 423.46246337890625,
      "y0": 442.6116943359375,
      "x1": 498.3297424316406,
      "y1": 453.775390625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 5,
    "line_count": 4,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -10.872772216796875,
    "vertical_space_before": -2.403167724609375,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "\u0013 \u0006\u0004",
    "bbox": {
      "x0": 385.49664306640625,
      "y0": 442.9026184082031,
      "x1": 392.9307861328125,
      "y1": 448.218994140625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.323333740234375,
    "vertical_space_before": -10.872772216796875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ">3\u000f\u0003'@",
    "bbox": {
      "x0": 324.980712890625,
      "y0": 444.8956604003906,
      "x1": 337.1747741699219,
      "y1": 450.24261474609375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -3.109893798828125,
    "vertical_space_before": -3.323333740234375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ">3\u000f\u0003'@",
    "bbox": {
      "x0": 534.2650146484375,
      "y0": 447.1327209472656,
      "x1": 546.458984375,
      "y1": 452.47967529296875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -0.379150390625,
    "vertical_space_before": -3.109893798828125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "4.9 (PEHGGLQJ /DQGPDUN",
    "bbox": {
      "x0": 323.9078369140625,
      "y0": 452.10052490234375,
      "x1": 368.4954528808594,
      "y1": 461.153564453125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.08,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 3,
    "line_count": 3,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -8.733734130859375,
    "vertical_space_before": -0.379150390625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "VZLWFK\u0003VRPH\u0003LPDJH\u0003SDWFKHV\u0003",
    "bbox": {
      "x0": 76.48516082763672,
      "y0": 452.4198303222656,
      "x1": 123.09727478027344,
      "y1": 456.70703125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -2.973175048828125,
    "vertical_space_before": -8.733734130859375,
    "label": "NONE",
    "language": "et"
  },
  {
    "text": "\u0015 \u0006\u0004",
    "bbox": {
      "x0": 423.4917297363281,
      "y0": 453.7338562011719,
      "x1": 431.0279235839844,
      "y1": 459.05023193359375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.24468994140625,
    "vertical_space_before": -2.973175048828125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0015 \u0006\u0004",
    "bbox": {
      "x0": 385.45318603515625,
      "y0": 453.8055419921875,
      "x1": 392.98931884765625,
      "y1": 459.1229248046875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -2.22869873046875,
    "vertical_space_before": -5.24468994140625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ")HDWXUHV",
    "bbox": {
      "x0": 325.1726989746094,
      "y0": 456.89422607421875,
      "x1": 337.00018310546875,
      "y1": 460.4588623046875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -3.181854248046875,
    "vertical_space_before": -2.22869873046875,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "2XW 0DW0XO",
    "bbox": {
      "x0": 515.6917114257812,
      "y0": 457.2770080566406,
      "x1": 542.9765625,
      "y1": 460.8507385253906
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.418701171875,
    "vertical_space_before": -3.181854248046875,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "ZLWK\u0003ODQGPDUN\u0003SDWFKHV",
    "bbox": {
      "x0": 80.88550567626953,
      "y0": 457.4320373535156,
      "x1": 118.68647003173828,
      "y1": 461.71923828125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -3.229736328125,
    "vertical_space_before": -3.418701171875,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "ǆ\u0003E",
    "bbox": {
      "x0": 276.7001953125,
      "y0": 458.489501953125,
      "x1": 282.15155029296875,
      "y1": 462.7767028808594
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "Calibri",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 1.97625732421875,
    "vertical_space_before": -3.229736328125,
    "label": "NONE",
    "language": "es"
  },
  {
    "text": "\u0014 \u0006\u0004",
    "bbox": {
      "x0": 423.6664733886719,
      "y0": 464.7529602050781,
      "x1": 430.86834716796875,
      "y1": 470.0703430175781
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.23052978515625,
    "vertical_space_before": 1.97625732421875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0014 \u0006\u0004",
    "bbox": {
      "x0": 385.64105224609375,
      "y0": 464.8398132324219,
      "x1": 392.8439025878906,
      "y1": 470.1571960449219
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.40771484375,
    "vertical_space_before": -5.23052978515625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0011\u0011\u0011",
    "bbox": {
      "x0": 97.73616790771484,
      "y0": 465.7494812011719,
      "x1": 101.76287841796875,
      "y1": 471.2419128417969
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.37,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -3.154205322265625,
    "vertical_space_before": -4.40771484375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "1RUP 06$ 1RUP 0/3",
    "bbox": {
      "x0": 153.60443115234375,
      "y0": 468.08770751953125,
      "x1": 256.60418701171875,
      "y1": 473.0433654785156
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.76,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 4,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.635650634765625,
    "vertical_space_before": -3.154205322265625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": ",PJ",
    "bbox": {
      "x0": 69.93714904785156,
      "y0": 468.40771484375,
      "x1": 76.6709213256836,
      "y1": 472.6949157714844
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.287200927734375,
    "vertical_space_before": -4.635650634765625,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "/0 ,PJ",
    "bbox": {
      "x0": 85.02975463867188,
      "y0": 468.40771484375,
      "x1": 128.36610412597656,
      "y1": 472.6949157714844
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.287200927734375,
    "vertical_space_before": -4.287200927734375,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": ",PJ",
    "bbox": {
      "x0": 106.7887954711914,
      "y0": 468.40771484375,
      "x1": 113.52172088623047,
      "y1": 472.6949157714844
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.247528076171875,
    "vertical_space_before": -4.287200927734375,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "/DQGPDUN\u0003VWUHDP",
    "bbox": {
      "x0": 330.5576477050781,
      "y0": 468.4473876953125,
      "x1": 367.2881164550781,
      "y1": 473.7943420410156
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 9.220123291015625,
    "vertical_space_before": -4.247528076171875,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "E \u0003&URVV\u0010DWWHQWLRQ\u0003WUDQVIRUPHU\u0003HQFRGHU\u0003 VXFK\u0003DV\u0003&URVV9L7",
    "bbox": {
      "x0": 114.99116516113281,
      "y0": 483.01446533203125,
      "x1": 236.4921112060547,
      "y1": 487.88128662109375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.76,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 3,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -1.611297607421875,
    "vertical_space_before": 9.220123291015625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "\u0013 \u0003\u0004\u0005",
    "bbox": {
      "x0": 386.2218017578125,
      "y0": 486.2699890136719,
      "x1": 395.859619140625,
      "y1": 491.58636474609375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.084075927734375,
    "vertical_space_before": -1.611297607421875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "0DW0XO 6FDOH 6RIW0D[ \u0013 \u0006\u0004",
    "bbox": {
      "x0": 423.5503845214844,
      "y0": 486.5022888183594,
      "x1": 498.3298034667969,
      "y1": 497.4477844238281
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 5,
    "line_count": 4,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -8.79376220703125,
    "vertical_space_before": -5.084075927734375,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": ">3\u000f\u0003'@",
    "bbox": {
      "x0": 325.79608154296875,
      "y0": 488.6540222167969,
      "x1": 337.9901123046875,
      "y1": 494.0009765625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -3.0628662109375,
    "vertical_space_before": -8.79376220703125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ">3\u000f\u0003'@",
    "bbox": {
      "x0": 534.3956298828125,
      "y0": 490.9381103515625,
      "x1": 546.5897216796875,
      "y1": 496.2850646972656
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -0.54144287109375,
    "vertical_space_before": -3.0628662109375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "4.9 (PEHGGLQJ ,PDJH )HDWXUHV",
    "bbox": {
      "x0": 325.9859619140625,
      "y0": 495.7436218261719,
      "x1": 369.310546875,
      "y1": 504.7966613769531
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 4,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -7.652008056640625,
    "vertical_space_before": -0.54144287109375,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "\u0015 \u0003\u0004\u0005",
    "bbox": {
      "x0": 386.2218017578125,
      "y0": 497.1446533203125,
      "x1": 395.9616394042969,
      "y1": 502.4610290527344
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.30224609375,
    "vertical_space_before": -7.652008056640625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0015 \u0003\u0004\u0005",
    "bbox": {
      "x0": 423.4625244140625,
      "y0": 497.1587829589844,
      "x1": 433.20233154296875,
      "y1": 502.4761962890625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.607147216796875,
    "vertical_space_before": -5.30224609375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "/0 /0 /0 \u0011\u0011\u0011 /0",
    "bbox": {
      "x0": 70.05648040771484,
      "y0": 500.8690490722656,
      "x1": 128.26113891601562,
      "y1": 507.8167724609375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 5,
    "line_count": 5,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -6.86737060546875,
    "vertical_space_before": -1.607147216796875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "2XW 0DW0XO",
    "bbox": {
      "x0": 515.6917114257812,
      "y0": 500.94940185546875,
      "x1": 542.9765625,
      "y1": 504.523193359375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.48,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -2.858734130859375,
    "vertical_space_before": -6.86737060546875,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "1RUP &URVV\u0010)XVLRQ",
    "bbox": {
      "x0": 149.11495971679688,
      "y0": 501.6644592285156,
      "x1": 192.2318878173828,
      "y1": 508.1651306152344
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.58,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.880950927734375,
    "vertical_space_before": -2.858734130859375,
    "label": "NONE",
    "language": "ro"
  },
  {
    "text": "06$ 1RUP 0/3",
    "bbox": {
      "x0": 178.82192993164062,
      "y0": 503.2841796875,
      "x1": 256.1416320800781,
      "y1": 509.62109375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.76,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 3,
    "line_count": 3,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -1.457244873046875,
    "vertical_space_before": -4.880950927734375,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "\u0014 \u0003\u0004\u0005",
    "bbox": {
      "x0": 386.2218017578125,
      "y0": 508.1638488769531,
      "x1": 395.6272888183594,
      "y1": 513.4810791015625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.30218505859375,
    "vertical_space_before": -1.457244873046875,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0014 \u0003\u0004\u0005",
    "bbox": {
      "x0": 423.4625244140625,
      "y0": 508.17889404296875,
      "x1": 432.8680114746094,
      "y1": 513.4952392578125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.34,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.958526611328125,
    "vertical_space_before": -5.30218505859375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": ",PDJH\u0003VWUHDP",
    "bbox": {
      "x0": 334.5926818847656,
      "y0": 511.5367126464844,
      "x1": 362.90704345703125,
      "y1": 516.8836669921875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 5.8758544921875,
    "vertical_space_before": -1.958526611328125,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "E \u00032XU\u0003SURSRVHG\u0003FURVV\u0010IXVLRQ\u000306$\u0003EORFN",
    "bbox": {
      "x0": 383.2889709472656,
      "y0": 522.759521484375,
      "x1": 476.043701171875,
      "y1": 528.1065063476562
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.23,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 3.982421875,
    "vertical_space_before": 5.8758544921875,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "Figure 4. (a) The vanilla MSA block in transformer encoder. (b) Our proposed cross-fusion MSA block in cross-fusion transformer encoder. P denotes the number of patches and D is the embedding dimension.",
    "bbox": {
      "x0": 313.6866149902344,
      "y0": 532.0889282226562,
      "x1": 552.2958984375,
      "y1": 574.344482421875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 32,
    "line_count": 4,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -37.50433349609375,
    "vertical_space_before": 3.982421875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": ",PJ ,PJ ,PJ \u0011\u0011\u0011 ,PJ",
    "bbox": {
      "x0": 69.93719482421875,
      "y0": 536.8401489257812,
      "x1": 128.6000213623047,
      "y1": 543.7879028320312
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.19,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 5,
    "line_count": 5,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -6.033203125,
    "vertical_space_before": -37.50433349609375,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "1RUP &URVV\u0010)XVLRQ",
    "bbox": {
      "x0": 149.11502075195312,
      "y0": 537.7546997070312,
      "x1": 192.23194885253906,
      "y1": 544.2564697265625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.58,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -4.8809814453125,
    "vertical_space_before": -6.033203125,
    "label": "NONE",
    "language": "ro"
  },
  {
    "text": "06$ 1RUP 0/3",
    "bbox": {
      "x0": 178.82199096679688,
      "y0": 539.37548828125,
      "x1": 256.1416931152344,
      "y1": 545.7113037109375
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.76,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 3,
    "line_count": 3,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 8.74224853515625,
    "vertical_space_before": -4.8809814453125,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "F \u00032XU\u0003SURSRVHG\u0003&URVV\u0010)XVLRQ\u0003WUDQVIRUPHU\u0003HQFRGHU",
    "bbox": {
      "x0": 115.93049621582031,
      "y0": 554.4535522460938,
      "x1": 235.56155395507812,
      "y1": 559.946044921875
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 5.37,
    "font_name": "TimesNewRomanPS-BoldMT",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 7.42578125,
    "vertical_space_before": 8.74224853515625,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "Figure 3. (a) The vanilla transformer encoder (from ViT [ 11 ]). (b) The cross-attention transformer encoder (such as CrossViT) (c) Our proposed cross-fusion transformer encoder.",
    "bbox": {
      "x0": 57.91700744628906,
      "y0": 567.371826171875,
      "x1": 296.5262145996094,
      "y1": 598.5608520507812
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 26,
    "line_count": 3,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -10.3985595703125,
    "vertical_space_before": 7.42578125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "landmark stream, the input X lm ∈ R P × D is mapped to three landmark matrices: query matrix Q lm , key matrix K lm and value matrix V lm by three linear transformations:",
    "bbox": {
      "x0": 313.6862487792969,
      "y0": 588.1622924804688,
      "x1": 552.3019409179688,
      "y1": 625.521728515625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 35,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -9.10113525390625,
    "vertical_space_before": -10.3985595703125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "way, we foster improved contextual understanding to allevi- ate intra-class discrepancy and inter-class similarity. There- fore, given the extracted image features X img and landmark features X lm , we design the cross-fusion MSA blocks as shown in Fig. 4 (b) to achieve our goal. Cross-fusion transformer encoder: For the MSA in the image stream, the input X img ∈ R P × D is mapped to three image matrices: query matrix Q img , key matrix K img and value matrix V img by three linear transformations. For the",
    "bbox": {
      "x0": 57.913875579833984,
      "y0": 616.4205932617188,
      "x1": 296.53265380859375,
      "y1": 723.35791015625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": true,
    "word_count": 90,
    "line_count": 9,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -86.4208984375,
    "vertical_space_before": -9.10113525390625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Q img = X img W Q 1 , K img = X img W K 1 , V img = X img W V 1 ,",
    "bbox": {
      "x0": 317.363037109375,
      "y0": 636.93701171875,
      "x1": 548.6180419921875,
      "y1": 646.9991455078125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "CMMI9",
    "is_bold": false,
    "is_italic": true,
    "word_count": 27,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 1.423583984375,
    "vertical_space_before": -86.4208984375,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "(5)",
    "bbox": {
      "x0": 541.7354125976562,
      "y0": 648.4227294921875,
      "x1": 552.2948608398438,
      "y1": 657.478759765625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 5.6202392578125,
    "vertical_space_before": 1.423583984375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "Q lm = X lm W Q 2 , K lm = X lm W K 2 , V lm = X lm W V 2 ,",
    "bbox": {
      "x0": 342.2666015625,
      "y0": 663.0989990234375,
      "x1": 548.6180419921875,
      "y1": 673.228759765625
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "CMMI9",
    "is_bold": false,
    "is_italic": true,
    "word_count": 27,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 1.35595703125,
    "vertical_space_before": 5.6202392578125,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "(6)",
    "bbox": {
      "x0": 541.7354125976562,
      "y0": 674.584716796875,
      "x1": 552.2948608398438,
      "y1": 683.6407470703125
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 12.079833984375,
    "vertical_space_before": 1.35595703125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "where W Q 1 , W Q 2 , W K 1 , W K 1 , W V 1 and W V 2 ∈ R D × D . The cross-fusion transformer block illustrated in Fig. 3",
    "bbox": {
      "x0": 316.2025146484375,
      "y0": 695.7205810546875,
      "x1": 552.3040771484375,
      "y1": 721.3418579101562
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 38,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 30.18115234375,
    "vertical_space_before": 12.079833984375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3149",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 4,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 30.18115234375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "(b) can be described as the following mapping functions:",
    "bbox": {
      "x0": 58.86394500732422,
      "y0": 72.28862762451172,
      "x1": 287.7694396972656,
      "y1": 82.3508529663086
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 9,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -10.038116455078125,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "method to alleviate inter-class similarity and intra-class dis- crepancy. Furthermore, we employ pyramid structures in POSTER to tackle scale-sensitivity, and therefore intelli- gently formulate a uniﬁed framework that addresses the three key challenges of FER. We verify the effectiveness of POSTER and its components in the following section.",
    "bbox": {
      "x0": 314.9250183105469,
      "y0": 72.31273651123047,
      "x1": 553.5405883789062,
      "y1": 142.74830627441406
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 48,
    "line_count": 6,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -56.70995330810547,
    "vertical_space_before": -10.038116455078125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "√",
    "bbox": {
      "x0": 233.29629516601562,
      "y0": 86.0383529663086,
      "x1": 241.67813110351562,
      "y1": 96.10057830810547
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMSY10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -3.0086898803710938,
    "vertical_space_before": -56.70995330810547,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "Attention ( img ) = Softmax( Q lm K ⊤",
    "bbox": {
      "x0": 70.44556427001953,
      "y0": 93.09188842773438,
      "x1": 220.59991455078125,
      "y1": 106.98357391357422
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.04,
    "font_name": "CMR7",
    "is_bold": false,
    "is_italic": true,
    "word_count": 10,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -13.891685485839844,
    "vertical_space_before": -3.0086898803710938,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "img /",
    "bbox": {
      "x0": 213.5986328125,
      "y0": 93.09188842773438,
      "x1": 233.29629516601562,
      "y1": 107.43196105957031
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -14.340072631835938,
    "vertical_space_before": -13.891685485839844,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "d ) V img , (7)",
    "bbox": {
      "x0": 241.68202209472656,
      "y0": 93.09188842773438,
      "x1": 297.47235107421875,
      "y1": 106.45307922363281
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 6,
    "line_count": 2,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -2.6609420776367188,
    "vertical_space_before": -14.340072631835938,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "√",
    "bbox": {
      "x0": 237.7362518310547,
      "y0": 103.7921371459961,
      "x1": 246.1180877685547,
      "y1": 113.85436248779297
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMSY10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -3.0086898803710938,
    "vertical_space_before": -2.6609420776367188,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "Attention ( lm ) = Softmax( Q img K ⊤",
    "bbox": {
      "x0": 79.12208557128906,
      "y0": 110.84567260742188,
      "x1": 229.4788360595703,
      "y1": 124.73735809326172
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.04,
    "font_name": "CMR7",
    "is_bold": false,
    "is_italic": true,
    "word_count": 10,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -13.891685485839844,
    "vertical_space_before": -3.0086898803710938,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "lm /",
    "bbox": {
      "x0": 222.4775390625,
      "y0": 110.84567260742188,
      "x1": 237.7362518310547,
      "y1": 125.18470764160156
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -14.339035034179688,
    "vertical_space_before": -13.891685485839844,
    "label": "NONE",
    "language": "sv"
  },
  {
    "text": "d ) V lm , (8)",
    "bbox": {
      "x0": 246.1219940185547,
      "y0": 110.84567260742188,
      "x1": 297.47235107421875,
      "y1": 124.20674133300781
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 6,
    "line_count": 2,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 11.441085815429688,
    "vertical_space_before": -14.339035034179688,
    "label": "NONE",
    "language": "ca"
  },
  {
    "text": "where 1 √",
    "bbox": {
      "x0": 58.85676193237305,
      "y0": 135.6478271484375,
      "x1": 94.1160659790039,
      "y1": 147.7266387939453
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.04,
    "font_name": "CMR7",
    "is_bold": false,
    "is_italic": true,
    "word_count": 3,
    "line_count": 3,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -10.065826416015625,
    "vertical_space_before": 11.441085815429688,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "d is the scaling factor for appropriate normalization to prevent extremely small gradients. The queries Q img and Q lm are swapped between the image and landmark streams. By doing this, the image features are empowered with salient regions provided by landmark features. On the other hand, the landmark features are provided with global information from the image features.",
    "bbox": {
      "x0": 58.85955047607422,
      "y0": 137.6608123779297,
      "x1": 297.478271484375,
      "y1": 221.4514923095703
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 59,
    "line_count": 7,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -64.97940063476562,
    "vertical_space_before": -10.065826416015625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "4. Experiments",
    "bbox": {
      "x0": 314.92987060546875,
      "y0": 156.4720916748047,
      "x1": 392.73956298828125,
      "y1": 168.54684448242188
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 12.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 8.209381103515625,
    "vertical_space_before": -64.97940063476562,
    "label": "H1",
    "language": "ca"
  },
  {
    "text": "4.1. Datasets",
    "bbox": {
      "x0": 314.92987060546875,
      "y0": 176.7562255859375,
      "x1": 374.2569885253906,
      "y1": 187.82470703125
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 11.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 8.2086181640625,
    "vertical_space_before": 8.209381103515625,
    "label": "H2",
    "language": "et"
  },
  {
    "text": "RAF-DB: Real-world Affective Faces Database (RAF-DB) [ 22 ] is a large-scale facial expression dataset with 29,672 real-world facial images. All images are collected from the Internet with great variability in the subject’s age, gen- der, ethnicity, lighting conditions, occlusions, etc. For the FER task, there are 15,339 facial expression images utilized (12,271 images are used for training and 3,068 images are used for testing) with seven basic expressions (happiness, surprise, sadness, anger, disgust, fear, and neutral). FERPlus: FERPlus [ 2 ] is extended from FER2013 [ 13 ] as used in the ICML 2013 Challenges. It is a large-scale dataset collected by APIs in the Google search engine. For the FER task, it contains 28,709 training images, 3,589 vali- dation images, and 3,589 testing images. FERPlus relabeled the FER2013 into eight emotion categories (seven basic ex- pressions plus contempt). Following [ 42 ] and [ 20 ], we re- port the overall accuracy on the test set. AffectNet: AffectNet [ 27 ] is one of the largest publicly available datasets for FER task. It is a large-scale in-the- wild dataset that contains more than 1M facial images col- lected from the Internet by querying three major search en- gines using 1250 emotion-related keywords in six different languages. Images are labeled into eight emotion categories (seven basic expressions plus contempt).",
    "bbox": {
      "x0": 314.92987060546875,
      "y0": 196.0333251953125,
      "x1": 553.5555419921875,
      "y1": 484.66192626953125
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 220,
    "line_count": 25,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -260.62440490722656,
    "vertical_space_before": 8.2086181640625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "The cross-fusion transformer encoder is shown in Fig. 3 (b). The outputs of the cross-fusion transformer encoder X img out and X lm out given the image features X img and landmark features X lm are represented as follows:",
    "bbox": {
      "x0": 58.85955047607422,
      "y0": 224.0375213623047,
      "x1": 297.4764404296875,
      "y1": 271.8328552246094
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 39,
    "line_count": 4,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 9.232208251953125,
    "vertical_space_before": -260.62440490722656,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "img = CFMSA img ( Q lm , K img , V img ) + X img , (9)",
    "bbox": {
      "x0": 79.17396545410156,
      "y0": 281.0650634765625,
      "x1": 297.47894287109375,
      "y1": 295.62664794921875
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI7",
    "is_bold": false,
    "is_italic": true,
    "word_count": 19,
    "line_count": 2,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -14.559112548828125,
    "vertical_space_before": 9.232208251953125,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "X ′",
    "bbox": {
      "x0": 70.83767700195312,
      "y0": 281.0675354003906,
      "x1": 82.28016662597656,
      "y1": 291.1297607421875
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 6.266265869140625,
    "vertical_space_before": -14.559112548828125,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "X img out = MLP(Norm( X ′",
    "bbox": {
      "x0": 70.8373794555664,
      "y0": 297.3960266113281,
      "x1": 189.18360900878906,
      "y1": 310.9833984375
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 7,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -13.584625244140625,
    "vertical_space_before": 6.266265869140625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "img )) + X ′",
    "bbox": {
      "x0": 186.07740783691406,
      "y0": 297.3987731933594,
      "x1": 232.3136444091797,
      "y1": 311.73876953125
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 5,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -14.339996337890625,
    "vertical_space_before": -13.584625244140625,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "img , (10)",
    "bbox": {
      "x0": 229.2074432373047,
      "y0": 297.3987731933594,
      "x1": 297.4761657714844,
      "y1": 311.73876953125
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 3,
    "line_count": 2,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 1.990966796875,
    "vertical_space_before": -14.339996337890625,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "X ′",
    "bbox": {
      "x0": 70.83463287353516,
      "y0": 313.729736328125,
      "x1": 82.28016662597656,
      "y1": 323.7919616699219
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -10.058441162109375,
    "vertical_space_before": 1.990966796875,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "lm = CFMSA lm ( Q img , K lm , V lm ) + X lm , (11) X lm out = MLP(Norm( X ′",
    "bbox": {
      "x0": 70.83757019042969,
      "y0": 313.7335205078125,
      "x1": 297.4790954589844,
      "y1": 342.4105529785156
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 26,
    "line_count": 3,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -13.5836181640625,
    "vertical_space_before": -10.058441162109375,
    "label": "NONE",
    "language": "sv"
  },
  {
    "text": "lm )) + X ′",
    "bbox": {
      "x0": 181.63845825195312,
      "y0": 328.8269348144531,
      "x1": 223.4337158203125,
      "y1": 343.1659240722656
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 5,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -14.3389892578125,
    "vertical_space_before": -13.5836181640625,
    "label": "NONE",
    "language": "ca"
  },
  {
    "text": "lm , (12)",
    "bbox": {
      "x0": 220.3275146484375,
      "y0": 328.8269348144531,
      "x1": 297.47967529296875,
      "y1": 343.1659240722656
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "CMMI10",
    "is_bold": false,
    "is_italic": true,
    "word_count": 3,
    "line_count": 2,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 11.531005859375,
    "vertical_space_before": -14.3389892578125,
    "label": "NONE",
    "language": "sv"
  },
  {
    "text": "where CFMSA( · ) represents the Cross-Fusion MSA block in the image stream or the landmark stream, Norm( · ) is the normalization operator, and MLP( · ) denotes the multilayer perceptron. Feature pyramid structure: In FER, the image quality and resolution often vary considerably. Therefore, to support applicability across image scales, we adapt the well-known and effective technique of feature pyramid structure [ 24 ] for producing a multi-scale feature representation. Speciﬁcally, we construct large/medium/small levels of extracted features as shown in Fig. 2 (b). The large/medium/small features are fed to separate cross- fusion transformer encoders to capture speciﬁc feature scales. The output of the three cross-fusion transformer en- coders is aggregated to form the emotion feature. Finally, an MLP head returns the predicted emotion label Y ∈ R N , where N is the number of classes. Distinction with other cross-attention design: There are some methods proposed cross-attention transformer such as CrossViT [ 8 ]. The goal is to switch the patches from two different modalities as illustrated in Fig 3 (b). Different from this CrossViT-style transformer encoder, the motiva- tion of our proposed cross-fusion transformer encoder is the feature collaboration. We enable the image features to be guided by some prior knowledge of salient regions from the landmarks. Meanwhile, the representations of the landmark stream are provided with global context from the image fea- tures while moving through the block operations. Take-away: Overall, we revitalize the idea of a two-stream architecture with our unique transformer-based cross-fusion",
    "bbox": {
      "x0": 58.86045837402344,
      "y0": 354.6969299316406,
      "x1": 297.4806823730469,
      "y1": 717.6795654296875
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": true,
    "word_count": 249,
    "line_count": 31,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -222.55520629882812,
    "vertical_space_before": 11.531005859375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "4.2. Implementation Details",
    "bbox": {
      "x0": 314.92987060546875,
      "y0": 495.1243591308594,
      "x1": 445.2834167480469,
      "y1": 506.1928405761719
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 11.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 3,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 8.252593994140625,
    "vertical_space_before": -222.55520629882812,
    "label": "H2",
    "language": "fr"
  },
  {
    "text": "We implemented POSTER with Pytorch [ 28 ] on two NVIDIA RTX 3090 GPUs. in an end-to-end manner. We utilized IR50 [ 10 ] as the image backbone, which is pre- trained on Ms-Celeb-1M dataset [ 14 ]. The weights of the image backbone are updated during training. For the fa- cial landmark detector, we select MobileFaceNet [ 7 ] with all of the weights frozen to ensure it outputs landmark features. In the feature pyramid structure, we produce large/medium/small extracted features with embedding dim D H = 512 , D M = 256 , and D L = 128 , respectively. For the cross-fusion transformer encoders, each level of en- coders consists of depth = 8 transformer encoders. The mlp ratio and drop path rate in transformer encoders are 2 and 0.01, receptively. We set the batch size to 100 with a learning rate of 4 × 10 − 5 . Unlike many methods [ 12 , 20 ] that rely on complicated loss, we use the standard label smoothing cross-entropy loss.",
    "bbox": {
      "x0": 314.9253845214844,
      "y0": 514.4454345703125,
      "x1": 553.5554809570312,
      "y1": 717.7026977539062
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 173,
    "line_count": 18,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 33.8203125,
    "vertical_space_before": 8.252593994140625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3150",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 5,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 33.8203125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "Table 1. Comparison on RAF-DB, AffectNet, and FERPlus datasets. “mean Acc” denotes mean class accuracy and “cls” is the abbreviation of classes.",
    "bbox": {
      "x0": 58.847557067871094,
      "y0": 72.54917907714844,
      "x1": 558.796630859375,
      "y1": 92.6717758178711
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 22,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 0.18610382080078125,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "RAF-DB AffectNet FERPlus Method Year Acc mean Acc Acc (7 cls) Acc (8 cls) Acc SCN[ 39 ] CVPR 2020 87.03 - - 60.23 89.39 PSR[ 37 ] CVPR 2020 88.98 80.78 63.77 60.68 - RAN[ 40 ] TIP 2020 86.90 - - - 89.16 DACL[ 12 ] WACV 2021 87.78 80.44 65.20 - - KTN[ 20 ] TIP 2021 88.07 - 63.97 - 90.49 DMUE[ 33 ] CVPR 2021 89.42 - 63.11 - - FDRL[ 30 ] CVPR 2021 89.47 - - - - ARM[ 34 ] arXiv 2021 90.42 82.77 65.20 61.33 - TransFER[ 42 ] ICCV 2021 90.91 - 66.23 - 90.83 Face2Exp[ 43 ] CVPR 2022 88.54 - 64.23 - - EAC[ 45 ] ECCV 2022 89.99 - 65.32 - 89.64 FER-former[ 23 ] arXiv 2023 91.30 - - - 90.96 Baseline - 91.00 84.64 65.06 60.94 90.91 POSTER - 92.05 86.03 67.31 63.34 91.62",
    "bbox": {
      "x0": 112.50833129882812,
      "y0": 92.85787963867188,
      "x1": 500.10052490234375,
      "y1": 290.44561767578125
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.33,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 149,
    "line_count": 108,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 17.36865234375,
    "vertical_space_before": 0.18610382080078125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "4.3. Comparison with State-of-the-art Results",
    "bbox": {
      "x0": 58.078670501708984,
      "y0": 307.81427001953125,
      "x1": 272.6523742675781,
      "y1": 318.88275146484375
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 11.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 5,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 22.871826171875,
    "vertical_space_before": 17.36865234375,
    "label": "H2",
    "language": "en"
  },
  {
    "text": "Evaluation on RAF-DB: Table 1 compares POSTER with previous methods on the RAF-DB dataset. POSTER out- performs the SOTA methods both in terms of accuracy (the accuracy of all samples) and mean accuracy (the average of the accuracy of each category). Our POSTER yields the highest accuracy of 92.05 %, which is 1.14 % better than the second-best method (TransFER [ 42 ]). Our POSTER also achieves the highest score of 86.03 % in mean accuracy, which is 3.26 % better than the second-best method (ARM [ 34 ], as TransFER did not report the mean accuracy).",
    "bbox": {
      "x0": 58.078670501708984,
      "y0": 341.75457763671875,
      "x1": 296.70428466796875,
      "y1": 460.53277587890625
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 97,
    "line_count": 10,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -60.701385498046875,
    "vertical_space_before": 22.871826171875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "D \u0003%DVHOLQH E \u00033267(5",
    "bbox": {
      "x0": 359.53485107421875,
      "y0": 399.8313903808594,
      "x1": 512.3619384765625,
      "y1": 406.18658447265625
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 6.21,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 6.078216552734375,
    "vertical_space_before": -60.701385498046875,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "Figure 5. Visualisation of high dimensional features using t- SNE[ 36 ] for the baseline and POSTER on the RAF-DB dataset.",
    "bbox": {
      "x0": 314.0,
      "y0": 412.2648010253906,
      "x1": 552.6090698242188,
      "y1": 432.3873596191406
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 21,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 17.6043701171875,
    "vertical_space_before": 6.078216552734375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "4.4. Results analysis",
    "bbox": {
      "x0": 314.0,
      "y0": 449.9917297363281,
      "x1": 408.0931701660156,
      "y1": 461.0602111816406
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 11.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 3,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 8.678802490234375,
    "vertical_space_before": 17.6043701171875,
    "label": "H2",
    "language": "en"
  },
  {
    "text": "In order to better understand the effectiveness of POSTER and its design, we perform further analysis on in- dividual class performance. Speciﬁcally, we ﬁrst analyze the class-speciﬁc evaluations of our baseline and POSTER on RAF-DB, FERPlus, and AffectNet (7 classes and 8 classes) in Tables 2 and 3 . For RAF-DB , the accuracy of Neutral, Happy, Sad, and Surprise categories of POSTER is higher than 90% as shown in Table 2 . However, the ac- curacy of Fear category is relatively low. This is due to insufﬁcient training samples on this category (281 of Fear images, while others such as Neutral, Happy, Sad, and Sur- prise are more than 1,000). Similar to the RAF-DB dataset, the accuracy of Disgust and Contempt categories in the FERPlus are relatively low as shown in Table 2 . This is also due to insufﬁcient training samples on these two cat- egories (only 116 of Disgust and 120 of Contempt, more than 20 × less than other categories). For AffectNet , all im- ages are collected from the internet, most of the training and testing samples are from in-the-wild settings. The ex- tremely unbalanced training set and challenging in-the-wild samples make the performance quite lower than in RAF-",
    "bbox": {
      "x0": 313.9998779296875,
      "y0": 469.739013671875,
      "x1": 552.62548828125,
      "y1": 721.2946166992188
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": true,
    "word_count": 204,
    "line_count": 21,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -243.73019409179688,
    "vertical_space_before": 8.678802490234375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Evaluation on AffectNet: Table 1 reports the results of POSTER with previous methods on the AffectNet dataset. AffectNet is the largest publicly available dataset with chal- lenging facial expressions. The training set is extremely un- balanced (134,415 happiness images but only 3,803 disgust images; the gap is over 35 × ). In terms of seven expres- sion categories, our POSTER achieves the best accuracy of 67.31 %, which is 1.08 % higher than the second-best method (TransFER [ 42 ]). When considering the Contempt category (total eight classes), Our POSTER also yields the highest accuracy of 63.34 %, which is 2.01 % better than the second-best method (ARM [ 34 ]).",
    "bbox": {
      "x0": 58.078670501708984,
      "y0": 477.5644226074219,
      "x1": 296.6943359375,
      "y1": 620.491943359375
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": true,
    "word_count": 111,
    "line_count": 12,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 17.03167724609375,
    "vertical_space_before": -243.73019409179688,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Evaluation on FERPlus: Table 1 evaluates POSTER with previous methods on FERPlus dataset. All images in FER- Plus are grayscale images with small resolutions (48×48). Our POSTER still achieves the best accuracy of 91.62 %, which is 0.79 % higher than the second-best method (Trans- FER [ 42 ]). Overall, the superior performance on all three datasets has demonstrated the effectiveness of POSTER.",
    "bbox": {
      "x0": 58.07863235473633,
      "y0": 637.5236206054688,
      "x1": 296.704345703125,
      "y1": 720.0824584960938
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 63,
    "line_count": 7,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 31.4405517578125,
    "vertical_space_before": 17.03167724609375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3151",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 6,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 31.4405517578125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "Table 2. Class-wise accuracy on RAF-DB, AffectNet, and FERPlus datasets. The blue color indicates the intra-class discrepancy has been reduced.",
    "bbox": {
      "x0": 58.92580795288086,
      "y0": 71.51005554199219,
      "x1": 558.8746337890625,
      "y1": 91.63265228271484
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 20,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 0.05548095703125,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "cls Acc mean Acc Dataset Method Neutral Happy Sad Surprise Fear Disgust Anger Contempt RAF-DB Baseline 90.44 96.71 90.38 87.23 62.16 76.25 88.89 - 84.58 POSTER 92.35 96.96 91.21 90.27 67.57 75.00 88.89 - 86.04 AffectNet",
    "bbox": {
      "x0": 90.56893920898438,
      "y0": 91.6881332397461,
      "x1": 524.7134399414062,
      "y1": 146.34046936035156
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.29,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 36,
    "line_count": 34,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -9.29443359375,
    "vertical_space_before": 0.05548095703125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Baseline 64.00 87.80 62.60 63.60 65.40 56.00 56.40 - 65.11 POSTER 67.20 89.00 67.00 64.00 64.80 56.00 62.60 - 67.23 AffectNet",
    "bbox": {
      "x0": 90.56893920898438,
      "y0": 137.04603576660156,
      "x1": 516.4601440429688,
      "y1": 169.0189971923828
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.29,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 21,
    "line_count": 21,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -20.819580078125,
    "vertical_space_before": -9.29443359375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "(7 cls) Baseline 57.20 74.60 61.20 63.00 63.40 61.40 52.00 54.71 60.94 POSTER 59.40 80.20 66.60 63.60 63.60 59.80 58.80 54.71 63.34",
    "bbox": {
      "x0": 97.28881072998047,
      "y0": 148.1994171142578,
      "x1": 516.4601440429688,
      "y1": 180.17250061035156
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.29,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 22,
    "line_count": 21,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -9.2945556640625,
    "vertical_space_before": -20.819580078125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "(8 cls) FERPlus Baseline 92.52 95.52 91.88 85.60 91.08 50.00 62.79 13.33 72.84 POSTER 93.26 96.08 92.39 85.86 91.45 43.75 68.60 33.33 75.59",
    "bbox": {
      "x0": 92.50288391113281,
      "y0": 170.87794494628906,
      "x1": 516.4601440429688,
      "y1": 202.85096740722656
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.29,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 23,
    "line_count": 22,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 12.853790283203125,
    "vertical_space_before": -9.2945556640625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "Table 3. Prediction details given the target class on RAF-DB dataset. The blue color indicates the intra-class discrepancy has been reduced. The red color denotes the inter-class similarity has been allivated.",
    "bbox": {
      "x0": 58.92573928833008,
      "y0": 215.7047576904297,
      "x1": 558.8746948242188,
      "y1": 235.82728576660156
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 31,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 2.009735107421875,
    "vertical_space_before": 12.853790283203125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Ground truth Prediction Percentage Neutral Happy Sad Surprise Fear Disgust Anger Baseline Neutral 90.44 2.50 4.56 1.62 0.00 0.74 0.15 POSTER Neutral 92.35 1.91 4.26 1.32 0.00 0.15 0.00 Baseline Fear 2.70 5.41 10.81 14.86 62.16 2.70 1.35 POSTER Fear 4.05 2.70 9.46 12.16 67.57 2.70 1.35 Baseline Surprise 5.47 0.91 0.91 87.23 1.52 1.82 2.13 POSTER Surprise 2.74 0.91 0.30 90.27 2.43 1.82 1.52",
    "bbox": {
      "x0": 117.41143798828125,
      "y0": 237.83702087402344,
      "x1": 495.354248046875,
      "y1": 333.6300964355469
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 65,
    "line_count": 63,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 14.086883544921875,
    "vertical_space_before": 2.009735107421875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "DB and FERPlus datasets. The accuracy of Happy category achieves 80% in Table 2 since there are 134,415 happiness samples (almost 50 % of the total training images).",
    "bbox": {
      "x0": 58.92573928833008,
      "y0": 347.71697998046875,
      "x1": 297.5413818359375,
      "y1": 381.92852783203125
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 28,
    "line_count": 3,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -31.544281005859375,
    "vertical_space_before": 14.086883544921875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "RXWSXW",
    "bbox": {
      "x0": 397.5657958984375,
      "y0": 350.3842468261719,
      "x1": 410.14227294921875,
      "y1": 355.41876220703125
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.92,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.788116455078125,
    "vertical_space_before": -31.544281005859375,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "RXWSXW \u0002 \u0003\u0004\u0005",
    "bbox": {
      "x0": 443.1844482421875,
      "y0": 350.6306457519531,
      "x1": 527.7238159179688,
      "y1": 359.1675109863281
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.92,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 3,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -7.18621826171875,
    "vertical_space_before": -4.788116455078125,
    "label": "NONE",
    "language": "pl"
  },
  {
    "text": "0/3 KHDG",
    "bbox": {
      "x0": 383.0480651855469,
      "y0": 351.9812927246094,
      "x1": 392.0340881347656,
      "y1": 361.6929626464844
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -9.466217041015625,
    "vertical_space_before": -7.18621826171875,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "0/3 KHDG",
    "bbox": {
      "x0": 500.6261901855469,
      "y0": 352.22674560546875,
      "x1": 509.6130676269531,
      "y1": 361.93841552734375
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -9.41693115234375,
    "vertical_space_before": -9.466217041015625,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 349.81500244140625,
      "y0": 352.521484375,
      "x1": 368.79510498046875,
      "y1": 356.451171875
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.84,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.684234619140625,
    "vertical_space_before": -9.41693115234375,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 467.1880798339844,
      "y0": 352.7669372558594,
      "x1": 486.1643371582031,
      "y1": 356.6966247558594
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.84,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -2.624786376953125,
    "vertical_space_before": -3.684234619140625,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "\u0002 \u0006\u0004",
    "bbox": {
      "x0": 326.95867919921875,
      "y0": 354.07183837890625,
      "x1": 334.6982421875,
      "y1": 359.71490478515625
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.54,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -2.599151611328125,
    "vertical_space_before": -2.624786376953125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 352.1812744140625,
      "y0": 357.1157531738281,
      "x1": 366.4184265136719,
      "y1": 361.0454406738281
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.84,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.68426513671875,
    "vertical_space_before": -2.599151611328125,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 469.5543518066406,
      "y0": 357.3611755371094,
      "x1": 483.788818359375,
      "y1": 361.2908630371094
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.84,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 5.394744873046875,
    "vertical_space_before": -3.68426513671875,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "D \u0003/DQGPDUN\u00032QO\\",
    "bbox": {
      "x0": 350.307861328125,
      "y0": 366.68560791015625,
      "x1": 388.3084411621094,
      "y1": 371.7201232910156
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.92,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.96685791015625,
    "vertical_space_before": 5.394744873046875,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "E \u0003,PDJH\u00032QO\\",
    "bbox": {
      "x0": 466.1639709472656,
      "y0": 366.7532653808594,
      "x1": 496.5103759765625,
      "y1": 371.78778076171875
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.92,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 10.677337646484375,
    "vertical_space_before": -4.96685791015625,
    "label": "NONE",
    "language": "pt"
  },
  {
    "text": "&URVV\u0010)XVLRQ",
    "bbox": {
      "x0": 465.364990234375,
      "y0": 382.4651184082031,
      "x1": 488.7170104980469,
      "y1": 386.9263000488281
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.43389892578125,
    "vertical_space_before": 10.677337646484375,
    "label": "NONE",
    "language": "ca"
  },
  {
    "text": "&URVV\u0010)XVLRQ",
    "bbox": {
      "x0": 465.36505126953125,
      "y0": 382.4924011230469,
      "x1": 488.7170715332031,
      "y1": 386.9535827636719
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.955352783203125,
    "vertical_space_before": -4.43389892578125,
    "label": "NONE",
    "language": "ca"
  },
  {
    "text": "RXWSXW \u0002 \u0006\u0004 \u0002 \u0003\u0004\u0005",
    "bbox": {
      "x0": 324.0610046386719,
      "y0": 382.99822998046875,
      "x1": 409.40130615234375,
      "y1": 396.37890625
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.54,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 5,
    "line_count": 3,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -13.367523193359375,
    "vertical_space_before": -3.955352783203125,
    "label": "NONE",
    "language": "pl"
  },
  {
    "text": "RXWSXW \u0002 \u0006\u0004 \u0002 \u0003\u0004\u0005",
    "bbox": {
      "x0": 441.2976379394531,
      "y0": 383.0113830566406,
      "x1": 526.5703735351562,
      "y1": 396.39508056640625
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.54,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 5,
    "line_count": 3,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -13.356475830078125,
    "vertical_space_before": -13.367523193359375,
    "label": "NONE",
    "language": "pl"
  },
  {
    "text": "RXWSXW \u0002 \u0006\u0004 \u0002 \u0003\u0004\u0005",
    "bbox": {
      "x0": 441.2976989746094,
      "y0": 383.0386047363281,
      "x1": 526.5704345703125,
      "y1": 396.42236328125
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.54,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 5,
    "line_count": 3,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -12.48138427734375,
    "vertical_space_before": -13.356475830078125,
    "label": "NONE",
    "language": "pl"
  },
  {
    "text": "When comparing the class-wise accuracy in Table 2 , POSTER signiﬁcantly increases the accuracy of most of the categories on three datasets, which indicates that POSTER reduces intra-class discrepancy for FER (marked in blue color if the class accuracy has been improved). In Table 3 , we show the percentage of prediction given the target cat- egories. For example, given a total of 680 Neutral testing images, 628 images are correctly classiﬁed as Neutral by POSTER (92.35 %) and 13 images are classiﬁed incorrectly as Happy (1.91 %). The percentage of the wrong prediction into certain categories also decreases as marked in red color, which shows that POSTER alleviates intra-class discrep- ancy for FER. Moreover, we visualize the high dimensional features before ﬁnal output of our baseline and POSTER by t-SNE [ 36 ]. The improved separation across classes and density with class clusters also veriﬁes that POSTER alle- viates the intra-class discrepancy and inter-class similarity.",
    "bbox": {
      "x0": 58.92573928833008,
      "y0": 383.94097900390625,
      "x1": 297.55145263671875,
      "y1": 587.1978759765625
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 156,
    "line_count": 17,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -202.10372924804688,
    "vertical_space_before": -12.48138427734375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "0/3 KHDG",
    "bbox": {
      "x0": 501.0634460449219,
      "y0": 385.0941467285156,
      "x1": 510.0503234863281,
      "y1": 394.8058166503906
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -9.688446044921875,
    "vertical_space_before": -202.10372924804688,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 348.360595703125,
      "y0": 385.11737060546875,
      "x1": 370.07330322265625,
      "y1": 389.57855224609375
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.457122802734375,
    "vertical_space_before": -9.688446044921875,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "0/3 KHDG",
    "bbox": {
      "x0": 383.8954162597656,
      "y0": 385.1214294433594,
      "x1": 392.8814392089844,
      "y1": 394.8330993652344
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -9.711669921875,
    "vertical_space_before": -4.457122802734375,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "0/3 KHDG",
    "bbox": {
      "x0": 501.0635070800781,
      "y0": 385.1214294433594,
      "x1": 510.0503845214844,
      "y1": 394.8330993652344
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -7.11749267578125,
    "vertical_space_before": -9.711669921875,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 466.1848449707031,
      "y0": 387.7156066894531,
      "x1": 487.89324951171875,
      "y1": 392.1767883300781
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.43389892578125,
    "vertical_space_before": -7.11749267578125,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 466.1849060058594,
      "y0": 387.7428894042969,
      "x1": 487.893310546875,
      "y1": 392.2040710449219
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.836181640625,
    "vertical_space_before": -4.43389892578125,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 351.0817565917969,
      "y0": 390.3678894042969,
      "x1": 367.35430908203125,
      "y1": 394.8290710449219
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.862945556640625,
    "vertical_space_before": -1.836181640625,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 468.9060363769531,
      "y0": 392.96612548828125,
      "x1": 485.1785888671875,
      "y1": 397.42730712890625
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.43389892578125,
    "vertical_space_before": -1.862945556640625,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 468.9060974121094,
      "y0": 392.993408203125,
      "x1": 485.17864990234375,
      "y1": 397.45458984375
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 6.701019287109375,
    "vertical_space_before": -4.43389892578125,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "F \u0003%DVHOLQH",
    "bbox": {
      "x0": 355.83056640625,
      "y0": 404.1556091308594,
      "x1": 379.47802734375,
      "y1": 409.19012451171875
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.92,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.034515380859375,
    "vertical_space_before": 6.701019287109375,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "G \u0003%DVHOLQH\u0003\u000e\u0003&URVV)XVLRQ",
    "bbox": {
      "x0": 456.1982421875,
      "y0": 404.1556091308594,
      "x1": 509.9637756347656,
      "y1": 409.19012451171875
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.92,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 8.586944580078125,
    "vertical_space_before": -5.034515380859375,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "&URVV\u0010)XVLRQ 7UDQVIRUPHU",
    "bbox": {
      "x0": 469.7423095703125,
      "y0": 417.7770690917969,
      "x1": 484.3369445800781,
      "y1": 423.8409729003906
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 2.72,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -4.436767578125,
    "vertical_space_before": 8.586944580078125,
    "label": "NONE",
    "language": "ro"
  },
  {
    "text": "7UDQVIRUPHU (QFRGHUV",
    "bbox": {
      "x0": 352.2984313964844,
      "y0": 419.4042053222656,
      "x1": 365.9876708984375,
      "y1": 425.46807861328125
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 2.72,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.129302978515625,
    "vertical_space_before": -4.436767578125,
    "label": "NONE",
    "language": "so"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 471.943115234375,
      "y0": 424.3387756347656,
      "x1": 482.12298583984375,
      "y1": 427.1217956542969
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 2.72,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 8.701690673828125,
    "vertical_space_before": -1.129302978515625,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "&URVV\u0010)XVLRQ",
    "bbox": {
      "x0": 468.2929992675781,
      "y0": 435.823486328125,
      "x1": 485.7787780761719,
      "y1": 439.1798400878906
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.28,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.38787841796875,
    "vertical_space_before": 8.701690673828125,
    "label": "NONE",
    "language": "ca"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 350.9996032714844,
      "y0": 437.7919616699219,
      "x1": 367.2925109863281,
      "y1": 441.1483154296875
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.28,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.38775634765625,
    "vertical_space_before": -1.38787841796875,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 468.8934020996094,
      "y0": 439.76055908203125,
      "x1": 485.18621826171875,
      "y1": 443.1169128417969
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.28,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.38787841796875,
    "vertical_space_before": -1.38775634765625,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 353.03704833984375,
      "y0": 441.7290344238281,
      "x1": 365.26361083984375,
      "y1": 445.08538818359375
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.28,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.387786865234375,
    "vertical_space_before": -1.38787841796875,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 470.9308166503906,
      "y0": 443.6976013183594,
      "x1": 483.1573486328125,
      "y1": 447.053955078125
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.28,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 11.63665771484375,
    "vertical_space_before": -1.387786865234375,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "\u0002 \u0006\u0004 \u0002 \u0003\u0004\u0005",
    "bbox": {
      "x0": 323.814453125,
      "y0": 458.69061279296875,
      "x1": 333.8887023925781,
      "y1": 472.0743408203125
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.54,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -13.356475830078125,
    "vertical_space_before": 11.63665771484375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "\u0002 \u0006\u0004 \u0002 \u0003\u0004\u0005",
    "bbox": {
      "x0": 441.0512390136719,
      "y0": 458.7178649902344,
      "x1": 451.1255187988281,
      "y1": 472.1015930175781
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.54,
    "font_name": "CambriaMath",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -13.118011474609375,
    "vertical_space_before": -13.356475830078125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "RXWSXW &URVV\u0010)XVLRQ",
    "bbox": {
      "x0": 466.8294677734375,
      "y0": 458.98358154296875,
      "x1": 547.4473266601562,
      "y1": 463.5051574707031
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.84,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.793426513671875,
    "vertical_space_before": -13.118011474609375,
    "label": "NONE",
    "language": "pl"
  },
  {
    "text": "RXWSXW 7UDQVIRUPHU",
    "bbox": {
      "x0": 348.28778076171875,
      "y0": 459.71173095703125,
      "x1": 428.4462890625,
      "y1": 465.2002258300781
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.84,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -3.23895263671875,
    "vertical_space_before": -3.793426513671875,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "0/3 KHDG",
    "bbox": {
      "x0": 408.48577880859375,
      "y0": 461.9612731933594,
      "x1": 415.2306213378906,
      "y1": 469.25469970703125
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.28,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -7.2923583984375,
    "vertical_space_before": -3.23895263671875,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "0/3 KHDG",
    "bbox": {
      "x0": 527.7738647460938,
      "y0": 461.96234130859375,
      "x1": 534.5186767578125,
      "y1": 469.2557678222656
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.28,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -5.677947998046875,
    "vertical_space_before": -7.2923583984375,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "7UDQVIRUPHU",
    "bbox": {
      "x0": 467.55548095703125,
      "y0": 463.57781982421875,
      "x1": 486.5355529785156,
      "y1": 467.50750732421875
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.84,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -1.517974853515625,
    "vertical_space_before": -5.677947998046875,
    "label": "NONE",
    "language": "sw"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 351.00897216796875,
      "y0": 465.9895324707031,
      "x1": 367.2815246582031,
      "y1": 470.4507141113281
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.36,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -2.282501220703125,
    "vertical_space_before": -1.517974853515625,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "(QFRGHUV",
    "bbox": {
      "x0": 469.9217224121094,
      "y0": 468.168212890625,
      "x1": 484.15618896484375,
      "y1": 472.097900390625
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 3.84,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 9.81451416015625,
    "vertical_space_before": -2.282501220703125,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "H \u0003%DVHOLQH\u0003\u000e\u00033\\UDPLG\u0003",
    "bbox": {
      "x0": 345.8920593261719,
      "y0": 481.91241455078125,
      "x1": 392.68994140625,
      "y1": 486.9469299316406
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.92,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -5.034454345703125,
    "vertical_space_before": 9.81451416015625,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "I \u00033267(5",
    "bbox": {
      "x0": 472.6440124511719,
      "y0": 481.9124755859375,
      "x1": 497.1173400878906,
      "y1": 486.9469909667969
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 4.92,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 7.050201416015625,
    "vertical_space_before": -5.034454345703125,
    "label": "NONE",
    "language": "it"
  },
  {
    "text": "Figure 6. (a) Only use landmark features X lm for classiﬁcation. (b) Only use image features X img for classiﬁcation. (c) Our base- line in Sec. 3.1 . (d) Our baseline with replacing vanilla transformer encoders with proposed cross-fusion transformer encoders. (e) Our baseline with adding a pyramid structure. (f) Our proposed POSTER in Sec. 3.2 .",
    "bbox": {
      "x0": 314.97540283203125,
      "y0": 493.9971923828125,
      "x1": 553.5936279296875,
      "y1": 558.8070068359375
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 57,
    "line_count": 7,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 10.63189697265625,
    "vertical_space_before": 7.050201416015625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Table 4. Ablation study on the proposed components.",
    "bbox": {
      "x0": 336.2752990722656,
      "y0": 569.4389038085938,
      "x1": 532.2938232421875,
      "y1": 578.4949340820312
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 8,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 1.831787109375,
    "vertical_space_before": 10.63189697265625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "RAF-DB AffectNet Components Acc Acc(mean) 7 cls 8 cls (a) Landmark only 80.08 72.21 49.88 45.34 (b) Image only 90.51 82.73 64.95 56.60 (c) Baseline 91.00 84.64 65.06 60.94 (d) Baseline+pyramid 91.27 85.66 66.50 62.36 (e) Baseline+cross fusion 91.63 85.01 65.35 61.87 (f) POSTER 92.05 86.03 67.31 63.34",
    "bbox": {
      "x0": 320.1392517089844,
      "y0": 580.3267211914062,
      "x1": 546.054931640625,
      "y1": 661.8375244140625
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 8.6,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 48,
    "line_count": 37,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": -67.38848876953125,
    "vertical_space_before": 1.831787109375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "4.5. Ablation Study",
    "bbox": {
      "x0": 58.92573928833008,
      "y0": 594.4490356445312,
      "x1": 149.9530029296875,
      "y1": 605.5175170898438
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 11.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 3,
    "line_count": 1,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": 7.85064697265625,
    "vertical_space_before": -67.38848876953125,
    "label": "H2",
    "language": "en"
  },
  {
    "text": "We conduct the ablation study on RAF-DB and Affect- Net datasets to verify the contribution of the proposed struc- tures and the impact of hyperparameters on performance. More ablation studies are provided in the supplementary . Effectiveness of the architecture design: We investigate the different architectures of utilizing image features and landmark features and report the results in Table 4 . In Fig. 6 (a) and (b), we only use the landmark features and image features, respectively. Utilizing image features achieves",
    "bbox": {
      "x0": 58.925621032714844,
      "y0": 613.3681640625,
      "x1": 297.544189453125,
      "y1": 720.0277099609375
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 81,
    "line_count": 10,
    "is_in_table": true,
    "column": 1,
    "vertical_space_after": -32.95465087890625,
    "vertical_space_before": 7.85064697265625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "better results than landmark features. When concatenat- ing image features with landmark features as a baseline in Fig. 6 (c) (discussed in Sec. 3.1 ), the performance",
    "bbox": {
      "x0": 314.9801330566406,
      "y0": 687.0730590820312,
      "x1": 553.5958251953125,
      "y1": 721.2846069335938
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 27,
    "line_count": 5,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 30.2384033203125,
    "vertical_space_before": -32.95465087890625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3152",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 7,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": true,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 30.2384033203125,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "D \u00031HXWUDO",
    "bbox": {
      "x0": 119.92591857910156,
      "y0": 72.56193542480469,
      "x1": 153.4807891845703,
      "y1": 80.42420196533203
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.69,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -7.862266540527344,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "E \u0003+DSS\\\u0003 F \u00036DG\u0003 G \u00036XUSULVH H \u0003)HDU I \u0003'LVJXVW J \u0003$QJHU\u0003 K \u0003&RQWHPSW",
    "bbox": {
      "x0": 177.3807830810547,
      "y0": 72.56193542480469,
      "x1": 544.8173217773438,
      "y1": 80.42420196533203
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.69,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 14,
    "line_count": 7,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 20.910606384277344,
    "vertical_space_before": -7.862266540527344,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "პ ,QSXW",
    "bbox": {
      "x0": 83.2701187133789,
      "y0": 101.33480834960938,
      "x1": 98.88166809082031,
      "y1": 117.77032470703125
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.4,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 2,
    "line_count": 2,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 33.00700378417969,
    "vertical_space_before": 20.910606384277344,
    "label": "NONE",
    "language": "vi"
  },
  {
    "text": "ჟ 'HWHFWHG\u0003 )DFLFDO\u0003 /DQGPDUN",
    "bbox": {
      "x0": 75.24656677246094,
      "y0": 150.77732849121094,
      "x1": 106.88775634765625,
      "y1": 186.353515625
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.69,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 4,
    "line_count": 4,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 18.798690795898438,
    "vertical_space_before": 33.00700378417969,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "რ $WWHQWLRQ 9LVXOL]DWLRQ ODQGPDUN\u0003 VWUHDP",
    "bbox": {
      "x0": 72.48748016357422,
      "y0": 205.15220642089844,
      "x1": 109.67759704589844,
      "y1": 249.96630859375
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.69,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 5,
    "line_count": 5,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 14.19512939453125,
    "vertical_space_before": 18.798690795898438,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "ს $WWHQWLRQ 9LVXOL]DWLRQ ,PDJH\u0003 VWUHDP",
    "bbox": {
      "x0": 72.47979736328125,
      "y0": 264.16143798828125,
      "x1": 109.66991424560547,
      "y1": 308.9755554199219
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 7.69,
    "font_name": "TimesNewRomanPSMT",
    "is_bold": false,
    "is_italic": false,
    "word_count": 5,
    "line_count": 5,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 9.70233154296875,
    "vertical_space_before": 14.19512939453125,
    "label": "NONE",
    "language": "de"
  },
  {
    "text": "Figure 7. Attention visualization on facial images of different categories (images are from the AffectNet dataset).",
    "bbox": {
      "x0": 102.90843200683594,
      "y0": 318.6778869628906,
      "x1": 512.4144897460938,
      "y1": 327.73394775390625
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 16,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 15.47576904296875,
    "vertical_space_before": 9.70233154296875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "also obtains some global attention beyond landmarks from the image features, such as cheek and forehead areas in (iii, a), (iii, e), and (iii, h). For the image stream attention maps, the highlight areas indicate the discriminate patterns that led to a certain classiﬁcation. For example, the tears drop in (iv, c) is discovered, which indicates a sad expression. The forehead wrinkles in (iv, g) are highlighted which relates to an angry expression. Because landmark features are cross- fused as guidance, the attention can focus on important re- gions related to landmarks. Moreover, some areas such as between the eyebrows and above the brow are also captured by image-guided features to improve the indication of the expression. By integrating attention from both landmark and image streams, POSTER can effectively recognize fa- cial expressions with excellent performance.",
    "bbox": {
      "x0": 313.93780517578125,
      "y0": 343.209716796875,
      "x1": 552.5634155273438,
      "y1": 522.3172607421875
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 136,
    "line_count": 15,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -177.28125,
    "vertical_space_before": 15.47576904296875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "is better than image features only and landmark features only. When replacing the vanilla transformer attention blocks with our proposed cross-fusion transformer atten- tion blocks as shown in Fig. 6 (d), the performance can be boosted, which veriﬁes the effectiveness of our pro- posed cross-fusion design. Next, we report the performance with our pyramid structure illustrated in Fig. 6 (e). When comparing (c) with (d), and (e) with (f), the performance has improved because the pyramid structure can alleviate scale sensitivity issues given various input sizes and qual- ity of training samples. Finally, our POSTER in Fig. 6 (f) achieves the best results. Attention Visualization: In order to visualize the parts of the facial image that contributes to the category clariﬁca- tion, we apply the visualization method of [ 6 ] to visualize the attention maps in the transformer. The relevance score is computed for each attention head in each layer of the trans- former encoders, and these scores are then integrated by in- corporating both relevancy and gradient information. More details are discussed in [ 6 ].",
    "bbox": {
      "x0": 59.09159851074219,
      "y0": 345.0360107421875,
      "x1": 297.707275390625,
      "y1": 587.3645629882812
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": true,
    "is_italic": false,
    "word_count": 178,
    "line_count": 21,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -42.32550048828125,
    "vertical_space_before": -177.28125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "5. Conclusions",
    "bbox": {
      "x0": 313.9391784667969,
      "y0": 545.0390625,
      "x1": 388.416259765625,
      "y1": 557.11376953125
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 12.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 2,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 12.01068115234375,
    "vertical_space_before": -42.32550048828125,
    "label": "H1",
    "language": "en"
  },
  {
    "text": "In this paper, we have proposed a Pyramid crOss-fuSion TransformER network (POSTER) for the FER task. As a two-stream network, landmark features are detected by an off-the-shelf facial landmark detector, and image fea- tures are extracted by a backbone CNN. The correlations of image features and landmark features are fully exploited in POSTER by our proposed cross-fusion transformer ar- chitecture. POSTER tackles all three challenges of inter- class similarity, intra-class discrepancy, and scale sensitiv- ity in FER. Extensive experiments on three commonly used FER datasets have demonstrated that POSTER outperforms state-of-the-art methods.",
    "bbox": {
      "x0": 313.9390563964844,
      "y0": 569.1244506835938,
      "x1": 552.564697265625,
      "y1": 712.008056640625
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 92,
    "line_count": 13,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -119.77337646484375,
    "vertical_space_before": 12.01068115234375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "The attention visualizations and detected facial land- marks for a set of facial images are shown in Fig. 7 . The images of 8 categories are selected from the in-the-wild AffectNet dataset. Since our proposed cross-fusion trans- former attention block has two streams (landmark and im- age), we visualize the attention map of each stream sepa- rately. The attention learned by these two streams are dif- ferent but complementary. For the landmark stream attention map, the highlight ar- eas are commonly from the landmark areas. However, it",
    "bbox": {
      "x0": 59.09159851074219,
      "y0": 592.2346801757812,
      "x1": 297.71728515625,
      "y1": 713.8165283203125
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 10.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 87,
    "line_count": 10,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 37.70648193359375,
    "vertical_space_before": -119.77337646484375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3153",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 8,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 37.70648193359375,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "References",
    "bbox": {
      "x0": 58.642906188964844,
      "y0": 72.18791198730469,
      "x1": 114.74220275878906,
      "y1": 84.26265716552734
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 12.07,
    "font_name": "NimbusRomNo9L-Medi",
    "is_bold": true,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -11.94720458984375,
    "vertical_space_before": 100,
    "label": "H1",
    "language": "en"
  },
  {
    "text": "learning contests. In International conference on neural in- formation processing , pages 117–124. Springer, 2013. 5 [14] Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, and",
    "bbox": {
      "x0": 313.22869873046875,
      "y0": 72.3154525756836,
      "x1": 551.8380737304688,
      "y1": 103.8656234741211
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 26,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -11.238441467285156,
    "vertical_space_before": -11.94720458984375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "[1] Mouath Aouayeb, Wassim Hamidouche, Catherine Soladie, Kidiyo Kpalma, and Renaud Seguier. Learning vision trans- former with squeeze and excitation for facial expression recognition. arXiv preprint arXiv:2107.03107 , 2021. 3 [2] Emad Barsoum, Cha Zhang, Cristian Canton Ferrer, and",
    "bbox": {
      "x0": 63.170738220214844,
      "y0": 92.62718200683594,
      "x1": 297.25189208984375,
      "y1": 146.6555938720703
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 39,
    "line_count": 5,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -40.779510498046875,
    "vertical_space_before": -11.238441467285156,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Jianfeng Gao. Ms-celeb-1m: A dataset and benchmark for large-scale face recognition. In European conference on computer vision , pages 87–102. Springer, 2016. 5 [15] Behzad Hasani and Mohammad H Mahoor. Facial expres- Zhengyou Zhang. Training deep networks for facial expres- sion recognition with crowd-sourced label distribution. In ACM International Conference on Multimodal Interaction (ICMI) , 2016. 5 [3] Stefano Berretti, Boulbaba Ben Amor, Mohamed Daoudi,",
    "bbox": {
      "x0": 63.170738220214844,
      "y0": 105.87608337402344,
      "x1": 551.8469848632812,
      "y1": 202.6945343017578
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 65,
    "line_count": 10,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -52.235443115234375,
    "vertical_space_before": -40.779510498046875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "sion recognition using enhanced deep 3d convolutional neu- ral networks. In Proceedings of the IEEE conference on com- puter vision and pattern recognition workshops , 2017. 1 , 2 [16] Haibo Jin, Shengcai Liao, and Ling Shao. Pixel-in-pixel net: Towards efﬁcient facial landmark detection in the wild. In- ternational Journal of Computer Vision , 2021. 2 [17] Heechul Jung, Sihaeng Lee, Junho Yim, Sunjeong Park, and",
    "bbox": {
      "x0": 313.249267578125,
      "y0": 150.45909118652344,
      "x1": 551.8675537109375,
      "y1": 226.6433868408203
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 66,
    "line_count": 7,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -21.938385009765625,
    "vertical_space_before": -52.235443115234375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "and Alberto Del Bimbo. 3d facial expression recognition us- ing sift descriptors of automatically detected keypoints. The Visual Computer , 27(11):1021–1036, 2011. 1 [4] Pierluigi Carcagn`ı, Marco Del Coco, Marco Leo, and",
    "bbox": {
      "x0": 63.170738220214844,
      "y0": 204.7050018310547,
      "x1": 297.25189208984375,
      "y1": 247.6669464111328
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 32,
    "line_count": 4,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -19.013092041015625,
    "vertical_space_before": -21.938385009765625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Junmo Kim. Joint ﬁne-tuning in deep neural networks for facial expression recognition. In Proceedings of the IEEE international conference on computer vision , 2015. 1 , 2 [18] Fuzail Khan. Facial expression recognition using facial land-",
    "bbox": {
      "x0": 313.249267578125,
      "y0": 228.6538543701172,
      "x1": 551.8674926757812,
      "y1": 271.2264099121094
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 36,
    "line_count": 4,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -21.548995971679688,
    "vertical_space_before": -19.013092041015625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Cosimo Distante. Facial expression recognition and his- tograms of oriented gradients: a comprehensive study. SpringerPlus , 4(1):1–25, 2015. 1 [5] Prashanth Chandran, Derek Bradley, Markus Gross, and",
    "bbox": {
      "x0": 63.170738220214844,
      "y0": 249.6774139404297,
      "x1": 297.2608947753906,
      "y1": 292.6393737792969
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 27,
    "line_count": 6,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -19.402496337890625,
    "vertical_space_before": -21.548995971679688,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "mark detection and feature extraction via neural networks. arXiv preprint arXiv:1812.04510 , 2018. 3 [19] Muhammad Haris Khan, John McDonagh, and Georgios Tz-",
    "bbox": {
      "x0": 313.249267578125,
      "y0": 273.23687744140625,
      "x1": 551.86767578125,
      "y1": 304.742919921875
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 23,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -10.09307861328125,
    "vertical_space_before": -19.402496337890625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Thabo Beeler. Attention-driven cropping for very high resolution facial landmark detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 5861–5870, 2020. 2 [6] Hila Chefer, Shir Gur, and Lior Wolf. Transformer inter-",
    "bbox": {
      "x0": 63.170738220214844,
      "y0": 294.64984130859375,
      "x1": 297.25189208984375,
      "y1": 348.67828369140625
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 38,
    "line_count": 7,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -41.9249267578125,
    "vertical_space_before": -10.09307861328125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "imiropoulos. Synergy between face alignment and tracking via discriminative global consensus optimization. In 2017 IEEE International Conference on Computer Vision (ICCV) , pages 3811–3819. IEEE, 2017. 2 [20] Hangyu Li, Nannan Wang, Xinpeng Ding, Xi Yang, and",
    "bbox": {
      "x0": 313.2402038574219,
      "y0": 306.75335693359375,
      "x1": 551.8584594726562,
      "y1": 360.3924255371094
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 37,
    "line_count": 5,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -9.747772216796875,
    "vertical_space_before": -41.9249267578125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "pretability beyond attention visualization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 782–791, 2021. 8 [7] Cunjian Chen. PyTorch Face Landmark: A fast and accurate",
    "bbox": {
      "x0": 63.170738220214844,
      "y0": 350.6446533203125,
      "x1": 297.2518615722656,
      "y1": 393.6507263183594
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 31,
    "line_count": 4,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -31.24786376953125,
    "vertical_space_before": -9.747772216796875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Xinbo Gao. Adaptively learning facial expression represen- tation via cf labels and distillation. IEEE Transactions on Image Processing , 30:2016–2028, 2021. 1 , 5 , 6 [21] Shan Li and Weihong Deng. Deep facial expression recog-",
    "bbox": {
      "x0": 313.2402038574219,
      "y0": 362.4028625488281,
      "x1": 551.8495483398438,
      "y1": 404.9754333496094
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 36,
    "line_count": 4,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -9.31427001953125,
    "vertical_space_before": -31.24786376953125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "facial landmark detector, 2021. 3 , 4 , 5 [8] Chun-Fu Richard Chen, Quanfu Fan, and Rameswar Panda.",
    "bbox": {
      "x0": 63.170738220214844,
      "y0": 395.6611633300781,
      "x1": 297.25189208984375,
      "y1": 416.4901123046875
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 18,
    "line_count": 2,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -9.54833984375,
    "vertical_space_before": -9.31427001953125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "nition: A survey. IEEE transactions on affective computing , 13(3):1195–1215, 2020. 1 [22] Shan Li, Weihong Deng, and JunPing Du. Reliable crowd-",
    "bbox": {
      "x0": 313.2402038574219,
      "y0": 406.9417724609375,
      "x1": 551.8495483398438,
      "y1": 438.491943359375
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 22,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -19.99139404296875,
    "vertical_space_before": -9.54833984375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Crossvit: Cross-attention multi-scale vision transformer for image classiﬁcation. In Proceedings of the IEEE/CVF in- ternational conference on computer vision , pages 357–366, 2021. 5 [9] Navneet Dalal and Bill Triggs. Histograms of oriented gra-",
    "bbox": {
      "x0": 63.170738220214844,
      "y0": 418.50054931640625,
      "x1": 297.2608947753906,
      "y1": 472.529052734375
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 34,
    "line_count": 5,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -32.02667236328125,
    "vertical_space_before": -19.99139404296875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "sourcing and deep locality-preserving learning for expres- sion recognition in the wild. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2584–2593. IEEE, 2017. 5 [23] Yande Li, Mingjie Wang, Minglun Gong, Yonggang Lu,",
    "bbox": {
      "x0": 313.23114013671875,
      "y0": 440.50238037109375,
      "x1": 551.8529663085938,
      "y1": 494.14141845703125
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 38,
    "line_count": 5,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -19.646026611328125,
    "vertical_space_before": -32.02667236328125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "dients for human detection. In 2005 IEEE computer soci- ety conference on computer vision and pattern recognition (CVPR’05) . Ieee, 2005. 1 [10] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos",
    "bbox": {
      "x0": 58.64270782470703,
      "y0": 474.4953918457031,
      "x1": 297.2608947753906,
      "y1": 517.5014038085938
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 31,
    "line_count": 4,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -21.349517822265625,
    "vertical_space_before": -19.646026611328125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "and Li Liu. Fer-former: Multi-modal transformer for facial expression recognition. arXiv preprint arXiv:2303.12997 , 2023. 6 [24] Tsung-Yi Lin, Piotr Doll´ar, Ross Girshick, Kaiming He,",
    "bbox": {
      "x0": 313.23114013671875,
      "y0": 496.1518859863281,
      "x1": 551.849365234375,
      "y1": 538.724365234375
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 25,
    "line_count": 5,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -19.21246337890625,
    "vertical_space_before": -21.349517822265625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Zafeiriou. Arcface: Additive angular margin loss for deep face recognition. In Proceedings of the IEEE/CVF con- ference on computer vision and pattern recognition , pages 4690–4699, 2019. 3 , 4 , 5 [11] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,",
    "bbox": {
      "x0": 58.633644104003906,
      "y0": 519.5119018554688,
      "x1": 297.25189208984375,
      "y1": 573.5403442382812
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 39,
    "line_count": 6,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -32.80548095703125,
    "vertical_space_before": -19.21246337890625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Bharath Hariharan, and Serge Belongie. Feature pyra- mid networks for object detection. In Proceedings of the IEEE conference on computer vision and pattern recogni- tion , pages 2117–2125, 2017. 2 , 5 [25] Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha",
    "bbox": {
      "x0": 313.23114013671875,
      "y0": 540.73486328125,
      "x1": 551.8494873046875,
      "y1": 594.3739013671875
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 42,
    "line_count": 7,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -18.82305908203125,
    "vertical_space_before": -32.80548095703125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. ICLR , 2021. 3 , 4 [12] Amir Hossein Farzaneh and Xiaojun Qi. Facial expression",
    "bbox": {
      "x0": 58.624595642089844,
      "y0": 575.5508422851562,
      "x1": 297.2518005371094,
      "y1": 640.645751953125
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 47,
    "line_count": 6,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -44.2613525390625,
    "vertical_space_before": -18.82305908203125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Raj, and Le Song. Sphereface: Deep hypersphere embedding for face recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 212–220, 2017. 2 [26] David G Lowe. Distinctive image features from scale- invariant keypoints. International journal of computer vi- sion , 60(2):91–110, 2004. 1 [27] Ali Mollahosseini, Behzad Hasani, and Mohammad H Ma-",
    "bbox": {
      "x0": 313.22210693359375,
      "y0": 596.3843994140625,
      "x1": 551.8493041992188,
      "y1": 683.5399169921875
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 58,
    "line_count": 9,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -40.92779541015625,
    "vertical_space_before": -44.2613525390625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "recognition in the wild via deep attentive center loss. In Pro- ceedings of the IEEE/CVF Winter Conference on Applica- tions of Computer Vision , pages 2402–2411, 2021. 2 , 5 , 6 [13] Ian J Goodfellow, Dumitru Erhan, Pierre Luc Carrier, Aaron",
    "bbox": {
      "x0": 58.624595642089844,
      "y0": 642.6121215820312,
      "x1": 297.23382568359375,
      "y1": 685.6181640625
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 42,
    "line_count": 4,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -0.0677490234375,
    "vertical_space_before": -40.92779541015625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "hoor. Affectnet: A database for facial expression, valence, and arousal computing in the wild. IEEE Transactions on Affective Computing , 10(1):18–31, 2017. 5",
    "bbox": {
      "x0": 333.3356018066406,
      "y0": 685.5504150390625,
      "x1": 551.831298828125,
      "y1": 716.7394409179688
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 23,
    "line_count": 3,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -29.11077880859375,
    "vertical_space_before": -0.0677490234375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Courville, Mehdi Mirza, Ben Hamner, Will Cukierski, Yichuan Tang, David Thaler, Dong-Hyun Lee, et al. Chal- lenges in representation learning: A report on three machine",
    "bbox": {
      "x0": 78.73811340332031,
      "y0": 687.628662109375,
      "x1": 297.23370361328125,
      "y1": 718.8176879882812
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 25,
    "line_count": 3,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 32.705322265625,
    "vertical_space_before": -29.11077880859375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3154",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 9,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 32.705322265625,
    "label": "NONE",
    "language": "unknown"
  },
  {
    "text": "[42] Fanglei Xue, Qiangchang Wang, and Guodong Guo. Trans-",
    "bbox": {
      "x0": 313.7621154785156,
      "y0": 72.35960388183594,
      "x1": 552.3806762695312,
      "y1": 81.4156723022461
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": false,
    "word_count": 9,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -8.598915100097656,
    "vertical_space_before": 100,
    "label": "NONE",
    "language": "tl"
  },
  {
    "text": "[28] Adam Paszke, Sam Gross, Soumith Chintala, Gregory fer: Learning relation-aware facial expression representa- tions with transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) , pages 3601–3610, October 2021. 2 , 3 , 5 , 6 [43] Dan Zeng, Zhiyuan Lin, Xiao Yan, Yuting Liu, Fei Wang,",
    "bbox": {
      "x0": 58.035316467285156,
      "y0": 72.81675720214844,
      "x1": 552.3715209960938,
      "y1": 137.75343322753906
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 51,
    "line_count": 6,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -53.870208740234375,
    "vertical_space_before": -8.598915100097656,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Al- ban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017. 5 [29] Yinghong Qiu and Yi Wan. Facial expression recognition based on landmarks. In 2019 IEEE 4th Advanced Informa- tion Technology, Electronic and Automation Control Confer- ence (IAEAC) . IEEE, 2019. 2 [30] Delian Ruan, Yan Yan, Shenqi Lai, Zhenhua Chai, Chunhua",
    "bbox": {
      "x0": 58.017208099365234,
      "y0": 83.88322448730469,
      "x1": 296.64447021484375,
      "y1": 171.09315490722656
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 62,
    "line_count": 8,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -31.329315185546875,
    "vertical_space_before": -53.870208740234375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "and Bo Tang. Face2exp: Combating data biases for facial ex- pression recognition. In Proceedings of the IEEE/CVF Con- ference on Computer Vision and Pattern Recognition , pages 20291–20300, 2022. 6 [44] Yuhang Zhang, Chengrui Wang, and Weihong Deng. Rel-",
    "bbox": {
      "x0": 313.7530517578125,
      "y0": 139.7638397216797,
      "x1": 552.371337890625,
      "y1": 194.09120178222656
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 39,
    "line_count": 5,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -20.987640380859375,
    "vertical_space_before": -31.329315185546875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Shen, and Hanzi Wang. Feature decomposition and recon- struction learning for effective facial expression recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 7660–7669, 2021. 2 , 6 [31] Caifeng Shan, Shaogang Gong, and Peter W McOwan. Ro-",
    "bbox": {
      "x0": 58.017208099365234,
      "y0": 173.1035614013672,
      "x1": 296.6380615234375,
      "y1": 237.83631896972656
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 44,
    "line_count": 6,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -41.734710693359375,
    "vertical_space_before": -20.987640380859375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "ative uncertainty learning for facial expression recogni- tion. Advances in Neural Information Processing Systems , 34:17616–17627, 2021. 2 [45] Yuhang Zhang, Chengrui Wang, Xu Ling, and Weihong bust facial expression recognition using local binary pat- terns. In IEEE International Conference on Image Process- ing 2005 , volume 2, pages II–370. IEEE, 2005. 1 [32] Caifeng Shan, Shaogang Gong, and Peter W McOwan. Fa-",
    "bbox": {
      "x0": 58.017208099365234,
      "y0": 196.1016082763672,
      "x1": 552.3622436523438,
      "y1": 282.4465026855469
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 63,
    "line_count": 8,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -41.07359313964844,
    "vertical_space_before": -41.734710693359375,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Deng. Learn from all: Erasing attention consistency for noisy label facial expression recognition. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Is- rael, October 23–27, 2022, Proceedings, Part XXVI , pages 418–434. Springer, 2022. 2 , 6 [46] Guoying Zhao and Matti Pietikainen. Dynamic texture recognition using local binary patterns with an application to facial expressions. IEEE transactions on pattern analysis and machine intelligence , 2007. 1 [47] Lin Zhong, Qingshan Liu, Peng Yang, Bo Liu, Junzhou",
    "bbox": {
      "x0": 313.72589111328125,
      "y0": 241.37290954589844,
      "x1": 552.353271484375,
      "y1": 352.03802490234375
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 78,
    "line_count": 13,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -67.5810546875,
    "vertical_space_before": -41.07359313964844,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "cial expression recognition based on local binary patterns: A comprehensive study. Image and vision Computing , 2009. 1 [33] Jiahui She, Yibo Hu, Hailin Shi, Jun Wang, Qiu Shen, and Tao Mei. Dive into ambiguity: latent distribution min- ing and pairwise uncertainty estimation for facial expression recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 6248– 6257, 2021. 3 , 6 [34] Jiawei Shi, Songhao Zhu, and Zhiwei Liang. Learning to",
    "bbox": {
      "x0": 57.999088287353516,
      "y0": 284.45697021484375,
      "x1": 296.62640380859375,
      "y1": 382.73333740234375
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 77,
    "line_count": 10,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": -28.68487548828125,
    "vertical_space_before": -67.5810546875,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "Huang, and Dimitris N Metaxas. Learning active facial patches for expression analysis. In 2012 IEEE Conference on Computer Vision and Pattern Recognition . IEEE, 2012. 1",
    "bbox": {
      "x0": 333.83941650390625,
      "y0": 354.0484619140625,
      "x1": 552.3350830078125,
      "y1": 385.237548828125
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 26,
    "line_count": 4,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": -0.4937744140625,
    "vertical_space_before": -28.68487548828125,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "amend facial expression representation via de-albino and afﬁnity. arXiv preprint arXiv:2103.10189 , 2021. 2 , 3 , 6 [35] Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf. Deepface: Closing the gap to human-level perfor- mance in face veriﬁcation. In 2014 IEEE Conference on Computer Vision and Pattern Recognition , 2014. 2 [36] Laurens Van der Maaten and Geoffrey Hinton. Visualiz- ing data using t-sne. Journal of machine learning research , 9(11), 2008. 6 , 7 [37] Thanh-Hung Vo, Guee-Sang Lee, Hyung-Jeong Yang, and Soo-Hyung Kim. Pyramid with super resolution for in-the- wild facial expression recognition. IEEE Access , 8:131988– 132001, 2020. 1 , 2 , 6 [38] Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, Wenyu Liu, and Bin Xiao. Deep high-resolution representation learning for visual recogni- tion. TPAMI , 2019. 2 [39] Kai Wang, Xiaojiang Peng, Jianfei Yang, Shijian Lu, and Yu Qiao. Suppressing uncertainties for large-scale facial ex- pression recognition. In Proceedings of the IEEE/CVF Con- ference on Computer Vision and Pattern Recognition , pages 6897–6906, 2020. 1 , 2 , 6 [40] Kai Wang, Xiaojiang Peng, Jianfei Yang, Debin Meng, and Yu Qiao. Region attention networks for pose and occlusion robust facial expression recognition. IEEE Transactions on Image Processing , 29:4057–4069, 2020. 1 , 2 , 6 [41] Qingzhong Wang, Pengfei Zhang, Haoyi Xiong, and Jian Zhao. Face. evolve: A high-performance face recognition library. arXiv preprint arXiv:2107.08621 , 2021. 2",
    "bbox": {
      "x0": 57.97193145751953,
      "y0": 384.7437744140625,
      "x1": 296.6573181152344,
      "y1": 717.1976318359375
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.06,
    "font_name": "NimbusRomNo9L-Regu",
    "is_bold": false,
    "is_italic": true,
    "word_count": 246,
    "line_count": 34,
    "is_in_table": false,
    "column": 1,
    "vertical_space_after": 34.32537841796875,
    "vertical_space_before": -0.4937744140625,
    "label": "NONE",
    "language": "en"
  },
  {
    "text": "3155",
    "bbox": {
      "x0": 297.0,
      "y0": 751.5230102539062,
      "x1": 315.0,
      "y1": 763.5289916992188
    },
    "page_number": 10,
    "page_width": 612.0,
    "page_height": 792.0,
    "font_size": 9.0,
    "font_name": "Times-Roman",
    "is_bold": false,
    "is_italic": false,
    "word_count": 1,
    "line_count": 1,
    "is_in_table": false,
    "column": 2,
    "vertical_space_after": 100,
    "vertical_space_before": 34.32537841796875,
    "label": "NONE",
    "language": "unknown"
  }
]